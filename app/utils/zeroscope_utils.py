import os
import torch
import subprocess
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict, Any, List

try:
    from diffusers import DiffusionPipeline
    from diffusers.utils import export_to_video
    import imageio
    import imageio_ffmpeg # videoio ëŒ€ì‹  imageio-ffmpeg ì‚¬ìš©
    ZEROSCOPE_AVAILABLE = True
    print("âœ… Zeroscope V2 ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    ZEROSCOPE_AVAILABLE = False
    print(f"âŒ Zeroscope V2 ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    print("ğŸ“Œ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:")
    print("pip install diffusers transformers accelerate")
    print("pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
    print("pip install imageio imageio-ffmpeg")


class ZeroscopeGenerator:

    """Zeroscope V2 Text-to-Video ìƒì„±ê¸°"""

    # Zeroscope V2 ëª¨ë¸ ID
    MODEL_ID_XL = "cerspense/zeroscope_v2_XL" # ë” í° ëª¨ë¸, ê³ í’ˆì§ˆ
    MODEL_ID_STANDARD = "cerspense/zeroscope_v2_576w" # <--- ì´ ë¶€ë¶„ì„ ìˆ˜ì •í•©ë‹ˆë‹¤! (ê¸°ì¡´: "cerspense/zeroscope_v2_576_320")

    def __init__(self, output_dir: str = "generated/videos", use_xl_model: bool = False):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        self.pipeline = None
        self.is_initialized = False
        self.use_xl_model = use_xl_model # ì´ ê°’ì— ë”°ë¼ self.model_idê°€ ê²°ì •ë¨
        self.model_id = self.MODEL_ID_XL if use_xl_model else self.MODEL_ID_STANDARD # <--- Standard ëª¨ë¸ ì‚¬ìš©
        
        if ZEROSCOPE_AVAILABLE:
            self._check_system_requirements()
    

    def _check_system_requirements(self) -> bool:
        """ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸"""
        if not torch.cuda.is_available():
            print("âŒ CUDA GPUê°€ í•„ìš”í•©ë‹ˆë‹¤. Zeroscope V2ëŠ” GPU ì—†ì´ëŠ” ë§¤ìš° ëŠë¦½ë‹ˆë‹¤.")
            return False
        
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
        if gpu_memory < 12 and self.use_xl_model: # XL ëª¨ë¸ì€ ë” ë§ì€ ë©”ëª¨ë¦¬ ìš”êµ¬
            print(f"âš ï¸ ê²½ê³ : XL ëª¨ë¸ ì‚¬ìš© ì‹œ GPU ë©”ëª¨ë¦¬({gpu_memory:.1f}GB)ê°€ ë¶€ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìµœì†Œ 12GB ê¶Œì¥.")
            print("ğŸ’¡ ì‘ì€ ëª¨ë¸(use_xl_model=False)ì„ ì‚¬ìš©í•˜ê±°ë‚˜ GPU ë©”ëª¨ë¦¬ë¥¼ í™•ë³´í•˜ì„¸ìš”.")
        elif gpu_memory < 6 and not self.use_xl_model: # Standard ëª¨ë¸ ë©”ëª¨ë¦¬ ìš”êµ¬
             print(f"âš ï¸ ê²½ê³ : Standard ëª¨ë¸ ì‚¬ìš© ì‹œ GPU ë©”ëª¨ë¦¬({gpu_memory:.1f}GB)ê°€ ë¶€ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìµœì†Œ 6GB ê¶Œì¥.")
        
        return True

    def initialize_pipeline(self) -> bool:
        """Zeroscope V2 íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”"""
        if not ZEROSCOPE_AVAILABLE:
            print("âŒ Zeroscope V2 ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False
        
        if self.is_initialized:
            return True
        
        try:
            print(f"ğŸ”„ Zeroscope V2 íŒŒì´í”„ë¼ì¸ ë¡œë”© ì¤‘... ({self.model_id})")
            
            # íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì‹œ device_map="auto"ë¥¼ ì‚¬ìš©í•˜ì—¬ ìë™ ë©”ëª¨ë¦¬ ë¶„ë°° í™œì„±í™”
            # local_files_only=False ì¶”ê°€í•˜ì—¬ ëˆ„ë½ëœ ëª¨ë¸ íŒŒì¼ ì¬ë‹¤ìš´ë¡œë“œ ì‹œë„
            self.pipeline = DiffusionPipeline.from_pretrained(
                self.model_id,
                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
                device_map="auto",
                local_files_only=False # <--- ì¶”ê°€: ëª¨ë¸ íŒŒì¼ ëˆ„ë½ ë¬¸ì œ í•´ê²° ì‹œë„
            )
            
            # GPUë¡œ ì´ë™ ë° ë©”ëª¨ë¦¬ ìµœì í™”
            if torch.cuda.is_available():
                # self.pipeline = self.pipeline.to("cuda") # <--- ì œê±°: ì´ ì¤„ì€ ë” ì´ìƒ í•„ìš” ì—†ìŠµë‹ˆë‹¤.
                print("ğŸš€ GPU ê°€ì† í™œì„±í™” ë° ë©”ëª¨ë¦¬ ìµœì í™” (ìë™ ë¶„ë°°)")
                
                # device_map="auto"ê°€ ëŒ€ë¶€ë¶„ì˜ ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ì²˜ë¦¬í•˜ë¯€ë¡œ
                # ì•„ë˜ ëª…ì‹œì ì¸ offload í˜¸ì¶œì€ í•„ìˆ˜ëŠ” ì•„ë‹ ìˆ˜ ìˆìœ¼ë‚˜, ì¶”ê°€ ìµœì í™”ë¥¼ ìœ„í•´ ìœ ì§€ ê°€ëŠ¥í•©ë‹ˆë‹¤.
                self.pipeline.enable_vae_slicing() 
                self.pipeline.enable_attention_slicing(1)
                self.pipeline.enable_model_cpu_offload() # í•„ìš”ì— ë”°ë¼ ìœ ì§€
                self.pipeline.enable_sequential_cpu_offload() # í•„ìš”ì— ë”°ë¼ ìœ ì§€
                
            else:
                print("âš ï¸ GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤. ë§¤ìš° ëŠë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            self.is_initialized = True
            print("âœ… Zeroscope V2 íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ Zeroscope V2 íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.pipeline = None
            return False

    def generate_video_from_prompt(self, 
                                   prompt: str, 
                                   duration: int = 30, # ìš”ì²­ëœ ê¸¸ì´
                                   quality: str = "balanced") -> Optional[str]:
        """
        í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ ì§ì ‘ Zeroscope V2 ë¹„ë””ì˜¤ ìƒì„±
        
        Args:
            prompt: ë¹„ë””ì˜¤ ìƒì„± í”„ë¡¬í”„íŠ¸
            duration: ìš”ì²­ëœ ë¹„ë””ì˜¤ ê¸¸ì´ (ì´ˆ) - Zeroscope V2ëŠ” ì´ ê¸¸ì´ë¥¼ ê³ ë ¤í•˜ì—¬ ìƒì„±
            quality: í’ˆì§ˆ ì„¤ì • ("fast", "balanced", "high")
            
        Returns:
            ìƒì„±ëœ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        """
        if not self.initialize_pipeline():
            return None
        
        # ğŸ”§ ìˆ˜ì •ë¨: ë©”ëª¨ë¦¬ ì •ë¦¬ ì¶”ê°€
        import gc
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
        gc.collect()
        
        # í’ˆì§ˆ ì„¤ì •ì— ë”°ë¥¸ íŒŒë¼ë¯¸í„° ì¡°ì •
        generation_params = self._get_quality_params(quality, duration)
        
        print(f"ğŸ¬ Zeroscope V2 ë¹„ë””ì˜¤ ìƒì„± ì‹œì‘... (ëª©í‘œ ê¸¸ì´: {duration}ì´ˆ)")
        print(f"ğŸ“‹ ì„¤ì •: {generation_params['num_inference_steps']}ë‹¨ê³„, {generation_params['num_frames']}í”„ë ˆì„, {generation_params['fps']}fps, {generation_params['width']}x{generation_params['height']} í•´ìƒë„")
        
        try:
            # Zeroscope V2ë¡œ ë¹„ë””ì˜¤ ìƒì„±
            video_frames = self.pipeline(
                prompt=prompt,
                num_inference_steps=generation_params['num_inference_steps'],
                num_frames=generation_params['num_frames'],
                guidance_scale=generation_params['guidance_scale'],
                width=generation_params['width'],
                height=generation_params['height'],
                generator=torch.Generator(device="cuda").manual_seed(42) if torch.cuda.is_available() else None
            ).frames[0]
            
            # ğŸ”§ ìˆ˜ì •ë¨: ìƒì„± í›„ ë©”ëª¨ë¦¬ ì •ë¦¬
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
            gc.collect()
            
            # íŒŒì¼ ì €ì¥
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = self.output_dir / f"zeroscope_{duration}s_{timestamp}.mp4"
            
            # ë¹„ë””ì˜¤ íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°
            export_to_video(video_frames, str(output_path), fps=generation_params['fps'])
            
            # ì‹¤ì œ íŒŒì¼ ì •ë³´ í™•ì¸
            file_size = output_path.stat().st_size / (1024*1024)
            actual_frames = len(video_frames)
            actual_duration = actual_frames / generation_params['fps']
            
            print(f"âœ… Zeroscope V2 ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {output_path}")
            print(f"ğŸ“Š ì‹¤ì œ ê²°ê³¼: {actual_frames}í”„ë ˆì„, {actual_duration:.1f}ì´ˆ, {file_size:.1f}MB")
            
            return str(output_path)
            
        except Exception as e:
            print(f"âŒ Zeroscope V2 ë¹„ë””ì˜¤ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            raise

    def _get_quality_params(self, quality: str, target_duration: int) -> Dict[str, Any]:
        """
        í’ˆì§ˆ ì„¤ì •ê³¼ ëª©í‘œ ê¸¸ì´ì— ë”°ë¥¸ ìƒì„± íŒŒë¼ë¯¸í„° ë°˜í™˜ (ğŸ”§ ìˆ˜ì •ë¨)
        """
        # Zeroscope V2ëŠ” num_framesë¡œ ì§ì ‘ ê¸¸ì´ë¥¼ ì¡°ì ˆí•©ë‹ˆë‹¤.
        # FPSëŠ” ê¸°ë³¸ 8~10 ì •ë„ë¡œ ì„¤ì •í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì´ë©°, ì—¬ê¸°ì„œëŠ” 8ë¡œ ê³ ì •í•©ë‹ˆë‹¤.
        base_fps = 8 
        
        # ğŸ”§ ìˆ˜ì •ë¨: í”„ë ˆì„ ìˆ˜ ê³„ì‚° ê³µì‹ ì™„ì „ ìˆ˜ì • (7ì´ˆ â†’ 30ì´ˆ ë¬¸ì œ í•´ê²°)
        # ê¸°ì¡´: num_frames = max(24, max(12, target_duration * 2))  # â† ì´ê²ƒì´ ë¬¸ì œì˜€ìŒ!
        # ìˆ˜ì •: ì‹¤ì œ durationì— ë§ëŠ” í”„ë ˆì„ ìˆ˜ ê³„ì‚°
        num_frames = min(256, max(24, target_duration * base_fps))  # 30ì´ˆ â†’ 240í”„ë ˆì„, ìµœëŒ€ 256í”„ë ˆì„ ì œí•œ
        
        quality_configs = {
            "fast": {
                "num_inference_steps": 15,  # ğŸ”§ ìˆ˜ì •ë¨: 20 â†’ 15 (ë” ë¹ ë¥´ê²Œ)
                "guidance_scale": 12.0,     # ğŸ”§ ìˆ˜ì •ë¨: 5.0 â†’ 12.0 (í”„ë¡¬í”„íŠ¸ ê°•í™”)
                "width": 384,
                "height": 256
            },
            "balanced": {
                "num_inference_steps": 20,
                "guidance_scale": 15.0,     # ğŸ”§ ìˆ˜ì •ë¨: 12.5 â†’ 15.0 (í”„ë¡¬í”„íŠ¸ ë” ê°•í™”)
                "width": 576,
                "height": 320
            },
            "high": {
                "num_inference_steps": 25,
                "guidance_scale": 17.5,     # ğŸ”§ ìˆ˜ì •ë¨: 7.0 â†’ 17.5 (í”„ë¡¬í”„íŠ¸ ìµœëŒ€ ê°•í™”)
                "width": 768,
                "height": 432
            }
        }
        
        config = quality_configs.get(quality, quality_configs["balanced"])
        
        # XL ëª¨ë¸ ì‚¬ìš© ì‹œ í•´ìƒë„ ì¡°ì •
        if self.use_xl_model:
            if quality == "fast": # XL ëª¨ë¸ì—ì„œëŠ” fastë„ í•´ìƒë„ ì¢€ ë†’ê²Œ
                config["width"] = 576
                config["height"] = 320
            elif quality == "balanced":
                config["width"] = 768
                config["height"] = 432
            elif quality == "high":
                config["width"] = 1024
                config["height"] = 576 # 16:9 ratio
        
        config["num_frames"] = num_frames
        config["fps"] = base_fps
        config["expected_duration"] = num_frames / base_fps # ì˜ˆìƒ ì‹¤ì œ ê¸¸ì´
        
        # ğŸ”§ ìˆ˜ì •ë¨: ë¡œê·¸ ë©”ì‹œì§€ ê°œì„ 
        print(f"ğŸ¥ ìˆ˜ì •ëœ ì„¤ì •: '{quality}' í’ˆì§ˆ, ëª©í‘œ {target_duration}ì´ˆ â†’ {config['expected_duration']:.1f}ì´ˆ ì˜ìƒ ({config['num_frames']}í”„ë ˆì„)")
        return config

def check_zeroscope_installation():
    """Zeroscope V2 ì„¤ì¹˜ ìƒíƒœ í™•ì¸"""
    return {
        "zeroscope_available": ZEROSCOPE_AVAILABLE,
        "cuda_available": torch.cuda.is_available() if ZEROSCOPE_AVAILABLE else False,
        "gpu_memory": torch.cuda.get_device_properties(0).total_memory / (1024**3) if ZEROSCOPE_AVAILABLE and torch.cuda.is_available() else 0,
        "model_in_use": ZeroscopeGenerator().model_id if ZEROSCOPE_AVAILABLE else "N/A", # í˜„ì¬ ì‚¬ìš© ëª¨ë¸
        "installation_guide": {
            "pytorch": "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118",
            "diffusers": "pip install diffusers transformers accelerate",
            "video_utils": "pip install imageio imageio-ffmpeg",
            "note": "CUDA GPUì™€ ìµœì†Œ 6GB VRAM í•„ìš” (XL ëª¨ë¸ì€ 12GB ì´ìƒ ê¶Œì¥)"
        },
        "recommended_settings": {
            "fast": "15ë‹¨ê³„, ë‚®ì€ í•´ìƒë„ (ë¹ ë¥¸ ìƒì„±, ë©”ëª¨ë¦¬ ì ˆì•½)",  # ğŸ”§ ìˆ˜ì •ë¨: 20â†’15
            "balanced": "20ë‹¨ê³„, ì¤‘ê°„ í•´ìƒë„ (ê· í˜• ì¡íŒ ìƒì„±, ê¶Œì¥)", 
            "high": "25ë‹¨ê³„, ë†’ì€ í•´ìƒë„ (ê³ í’ˆì§ˆ ìƒì„±, ë©”ëª¨ë¦¬ ë§ì´ ì‚¬ìš©)"
        },
        "duration_capability": "Zeroscope V2ëŠ” ìš”ì²­ëœ 'duration'ì„ ë°”íƒ•ìœ¼ë¡œ ë” ê¸´ ì˜ìƒì„ ì§ì ‘ ìƒì„±í•©ë‹ˆë‹¤. (ë‹¨, í”„ë ˆì„ ìˆ˜/FPSì— ì˜í•´ ìµœì¢… ê¸¸ì´ê°€ ê²°ì •ë¨)",
        "model_choices": {
            "XL_model": "cerspense/zeroscope_v2_XL (ë” ë†’ì€ í€„ë¦¬í‹°, ë” ë§ì€ GPU VRAM í•„ìš”)",
            "Standard_model": "cerspense/zeroscope_v2_576w (ë” ë¹ ë¦„, ì ì€ GPU VRAM)"  # ğŸ”§ ìˆ˜ì •ë¨: ëª¨ë¸ëª… ìˆ˜ì •
        }
    }

# í¸ì˜ í•¨ìˆ˜ë“¤ (main.pyì—ì„œ ì§ì ‘ í˜¸ì¶œí•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ë³€ê²½ ë¶ˆí•„ìš”)
def generate_ad_video_zeroscope(prompt: str, duration: int = 30, quality: str = "balanced") -> Optional[str]:
    """ê°„ë‹¨í•œ Zeroscope V2 ê´‘ê³  ë¹„ë””ì˜¤ ìƒì„± í•¨ìˆ˜"""
    generator = ZeroscopeGenerator()
    return generator.generate_video_from_prompt(prompt, duration=duration, quality=quality)