# app/utils/CogVideoX_2b_utils.py íŒŒì¼ ë‚´ìš©

import os # OS ê¸°ëŠ¥ (íŒŒì¼/ê²½ë¡œ ì¡°ì‘)
import subprocess # ì™¸ë¶€ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ (FFmpeg ë“±)
import math # ìˆ˜í•™ í•¨ìˆ˜ (ë‚˜ëˆ—ì…ˆ ì˜¬ë¦¼ ë“±) - ì¶”ê°€ ì„í¬íŠ¸
import shutil # íŒŒì¼/ë””ë ‰í† ë¦¬ ì¡°ì‘ìš© ì„í¬íŠ¸ ì¶”ê°€
from pathlib import Path # íŒŒì¼ ì‹œìŠ¤í…œ ê²½ë¡œ ê°ì²´ ì§€í–¥ì  ì²˜ë¦¬
from datetime import datetime # ë‚ ì§œ/ì‹œê°„ ì²˜ë¦¬
from typing import Optional, Dict, Any, List # íƒ€ì… íŒíŠ¸

# PyTorch ì„í¬íŠ¸ ë° ê°€ìš©ì„± í”Œë˜ê·¸: ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ PyTorch ë¡œë“œ.
try:
    import torch # PyTorch ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì‹œë„
    TORCH_AVAILABLE = True # ì„±ê³µ ì‹œ True
except ImportError as e:
    TORCH_AVAILABLE = False # ì‹¤íŒ¨ ì‹œ False
    print(f"âŒ PyTorch ë¡œë“œ ì‹¤íŒ¨: {e}")

# Diffusers ì„í¬íŠ¸ ë° RiffusionPipeline ê°€ìš©ì„± í”Œë˜ê·¸: í™•ì‚° ëª¨ë¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ.
# diffusers ì„í¬íŠ¸ ìˆ˜ì • (RiffusionPipeline ì§ì ‘ ì„í¬íŠ¸ ì‹œë„ ë¶€ë¶„ ì œê±°)
try:
    from diffusers import DiffusionPipeline # ê¸°ë³¸ í™•ì‚° íŒŒì´í”„ë¼ì¸ ì„í¬íŠ¸
    from diffusers.utils import export_to_video # ë¹„ë””ì˜¤ ë‚´ë³´ë‚´ê¸° ìœ í‹¸ë¦¬í‹° ì„í¬íŠ¸

    # RIFFUSION_PIPELINE_AVAILABLEì€ ì´ì œ initialize_riffusion_pipeline()ì—ì„œ ì„¤ì •í•  ê²ƒì„
    # ë”°ë¼ì„œ ì—¬ê¸°ì„œ RiffusionPipeline ì„í¬íŠ¸ ì‹œë„ ë¸”ë¡ì„ ì œê±°í•©ë‹ˆë‹¤.
    RIFFUSION_PIPELINE_AVAILABLE = True # ì´ˆê¸°ì—ëŠ” Trueë¡œ ë‘ê³ , ì´ˆê¸°í™” í•¨ìˆ˜ì—ì„œ ì‹¤ì œ ì—¬ë¶€ íŒë‹¨
    
    DIFFUSERS_AVAILABLE = True # Diffusers ëª¨ë“ˆ ì‚¬ìš© ê°€ëŠ¥
    print("âœ… Diffusers ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    DIFFUSERS_AVAILABLE = False # Diffusers ëª¨ë“ˆ ì‚¬ìš© ë¶ˆê°€ëŠ¥
    RIFFUSION_PIPELINE_AVAILABLE = False # Diffusers ìì²´ê°€ ì—†ìœ¼ë©´ Riffusionë„ ë¶ˆê°€
    print(f"âŒ Diffusers ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    print("ğŸ“Œ CogVideoX-2b ê¸°ëŠ¥ ì—†ì´ ê¸°ë³¸ ì´ë¯¸ì§€+ì˜¤ë””ì˜¤ í•©ì„± ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")


# ImageIO ì„í¬íŠ¸ ë° ê°€ìš©ì„± í”Œë˜ê·¸: ì´ë¯¸ì§€/ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬.
try:
    import imageio # imageio ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì‹œë„
    import imageio_ffmpeg # imageio-ffmpeg í”ŒëŸ¬ê·¸ì¸ ì„í¬íŠ¸ ì‹œë„
    IMAGEIO_AVAILABLE = True # ì„±ê³µ ì‹œ True
except ImportError as e:
    IMAGEIO_AVAILABLE = False # ì‹¤íŒ¨ ì‹œ False
    print(f"âŒ ImageIO ë¡œë“œ ì‹¤íŒ¨: {e}")

# SoundFile ì„í¬íŠ¸ ë° ê°€ìš©ì„± í”Œë˜ê·¸: ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥ ë¼ì´ë¸ŒëŸ¬ë¦¬ (Riffusion ê²°ê³¼ ì €ì¥ì— í•„ìš”).
try:
    import soundfile as sf # soundfile ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì‹œë„ (sf ë³„ì¹­)
    SOUNDFILE_AVAILABLE = True # ì„±ê³µ ì‹œ True
except ImportError as e:
    SOUNDFILE_AVAILABLE = False # ì‹¤íŒ¨ ì‹œ False
    print(f"âŒ SoundFile ë¡œë“œ ì‹¤íŒ¨ (Riffusion BGM ì €ì¥ ë¶ˆê°€): {e}")
    print("ğŸ“Œ 'pip install soundfile'ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

# BGM ìƒì„± ì „ì²´ ê°€ìš©ì„± í”Œë˜ê·¸: Riffusion íŒŒì´í”„ë¼ì¸ê³¼ SoundFile ëª¨ë‘ ìˆì–´ì•¼ BGM ìƒì„± ê°€ëŠ¥.
BGM_GENERATION_AVAILABLE = RIFFUSION_PIPELINE_AVAILABLE and SOUNDFILE_AVAILABLE # Riffusion BGM ìƒì„± ê°€ëŠ¥ ì—¬ë¶€ ìµœì¢… íŒë‹¨

# CogVideoX-2b ì „ì²´ ê°€ìš©ì„± í™•ì¸: PyTorch, Diffusers, ImageIO ëª¨ë‘ ìˆì–´ì•¼ CogVideoX ê¸°ëŠ¥ í™œì„±í™”.
COGVIDEODX_AVAILABLE = TORCH_AVAILABLE and DIFFUSERS_AVAILABLE and IMAGEIO_AVAILABLE # CogVideoX-2b ê¸°ëŠ¥ ê°€ëŠ¥ ì—¬ë¶€ ìµœì¢… íŒë‹¨

# CogVideoX-2b ì˜ì¡´ì„± ë¡œë“œ ê²°ê³¼ ì¶œë ¥ ë° ë¯¸ì„¤ì¹˜ ì‹œ ê°€ì´ë“œ ì œê³µ.
if COGVIDEODX_AVAILABLE:
    print("âœ… CogVideoX-2b ê¸°ë³¸ ì˜ì¡´ì„± ë¡œë“œ ì„±ê³µ")
else:
    print("âŒ CogVideoX-2b ì¼ë¶€ ê¸°ë³¸ ì˜ì¡´ì„± ëˆ„ë½")
    print("ğŸ“Œ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ìˆ˜ì •í•˜ì„¸ìš”:")
    if not TORCH_AVAILABLE: # PyTorchê°€ ì—†ìœ¼ë©´ ì„¤ì¹˜ ê°€ì´ë“œ
        print("pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")
    if not DIFFUSERS_AVAILABLE: # Diffusersê°€ ì—†ìœ¼ë©´ ì„¤ì¹˜ ê°€ì´ë“œ
        print("pip install 'numpy<2.0.0' --force-reinstall") # numpy ë²„ì „ ì¶©ëŒ ë°©ì§€
        print("pip install --upgrade huggingface-hub diffusers transformers accelerate")
    if not IMAGEIO_AVAILABLE: # ImageIOê°€ ì—†ìœ¼ë©´ ì„¤ì¹˜ ê°€ì´ë“œ
        print("pip install imageio imageio-ffmpeg")
    if not SOUNDFILE_AVAILABLE: # SoundFileì´ ì—†ìœ¼ë©´ ì„¤ì¹˜ ê°€ì´ë“œ
        print("pip install soundfile")

class CogVideoXGenerator:
    """CogVideoX-2b Text-to-Video ìƒì„±ê¸°: ë¹„ë””ì˜¤ ë° BGM ìƒì„± ë¡œì§."""

    MODEL_ID_COGVIDEODX = "THUDM/CogVideoX-2b" # CogVideoX ëª¨ë¸ ID
    RIFFUSION_MODEL_ID = "riffusion/riffusion-beta" # Riffusion ëª¨ë¸ ID

    def __init__(self, output_dir: str = "generated/videos", bgm_dir: str = "generated/bgm"):
        self.output_dir = Path(output_dir) # ë¹„ë””ì˜¤ ì¶œë ¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        self.output_dir.mkdir(parents=True, exist_ok=True) # ë””ë ‰í† ë¦¬ ìƒì„± (ì—†ìœ¼ë©´)
        self.bgm_dir = Path(bgm_dir) # BGM ì¶œë ¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        self.bgm_dir.mkdir(parents=True, exist_ok=True) # ë””ë ‰í† ë¦¬ ìƒì„± (ì—†ìœ¼ë©´)

        self.pipeline = None # CogVideoX íŒŒì´í”„ë¼ì¸ ê°ì²´ (ì´ˆê¸° None)
        self.riffusion_pipeline = None # Riffusion íŒŒì´í”„ë¼ì¸ ê°ì²´ (ì´ˆê¸° None)
        self.is_initialized = False # CogVideoX íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì—¬ë¶€ í”Œë˜ê·¸
        self.riffusion_initialized = False # Riffusion íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì—¬ë¶€ í”Œë˜ê·¸
        self.model_id = self.MODEL_ID_COGVIDEODX # ì‚¬ìš©í•  CogVideoX ëª¨ë¸ ID
        print(f"ğŸ”„ ì„¤ì •ëœ ë¹„ë””ì˜¤ ëª¨ë¸: {self.model_id}")

        if not COGVIDEODX_AVAILABLE: # CogVideoX ì˜ì¡´ì„±ì´ ë¶ˆì™„ì „í•˜ë©´ ê²½ê³ 
            print("âš ï¸ CogVideoX-2b ê¸°ë³¸ ì˜ì¡´ì„±ì´ ì™„ì „í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")
            return

        self._check_system_requirements() # ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ (GPU ë“±) í™•ì¸

    def _check_system_requirements(self) -> bool:
        """GPU ì „ìš© ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸: PyTorch, CUDA, GPU ë©”ëª¨ë¦¬ ë“±."""
        if not TORCH_AVAILABLE: # PyTorch ì„¤ì¹˜ ì—¬ë¶€ í™•ì¸
            print("âŒ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False

        if not torch.cuda.is_available(): # CUDA GPU ê°€ìš©ì„± í™•ì¸
            print("âŒ CUDA GPUê°€ í•„ìš”í•©ë‹ˆë‹¤. CogVideoX-2bëŠ” GPU ì „ìš©ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
            print("ğŸ”§ CUDA ì„¤ì¹˜ ê°€ì´ë“œ:") # CUDA ì„¤ì¹˜ ê°€ì´ë“œ ì œê³µ
            print("    1. NVIDIA ë“œë¼ì´ë²„ ì„¤ì¹˜: https://www.nvidia.com/drivers")
            print("    2. CUDA Toolkit ì„¤ì¹˜: https://developer.nvidia.com/cuda-downloads")
            print("    3. PyTorch CUDA ë²„ì „ ì¬ì„¤ì¹˜:")
            print("      pip uninstall torch torchvision torchaudio")
            print("      pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")
            return False

        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3) # GPU ë©”ëª¨ë¦¬ í™•ì¸ (GB)
        gpu_name = torch.cuda.get_device_name(0) # GPU ì´ë¦„ ê°€ì ¸ì˜¤ê¸°

        print(f"ğŸš€ GPU ê°ì§€: {gpu_name} ({gpu_memory:.1f}GB VRAM)")

        if gpu_memory < 8: # GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ê²½ê³ 
            print(f"âš ï¸ ê²½ê³ : GPU ë©”ëª¨ë¦¬({gpu_memory:.1f}GB)ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            print("ğŸ“Œ ìµœì†Œ 8GB VRAM ê¶Œì¥, 12GB ì´ìƒ ê¶Œì¥")
            print("ğŸ”§ í•´ê²°ë°©ë²•:") # í•´ê²° ë°©ë²• ì œì‹œ
            print("    - í’ˆì§ˆì„ 'fast'ë¡œ ì„¤ì •")
            print("    - ë‹¤ë¥¸ GPU í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
            print("    - ì‹œìŠ¤í…œ ì¬ë¶€íŒ…")
        else: # GPU ë©”ëª¨ë¦¬ ì¶©ë¶„
            print(f"âœ… GPU ë©”ëª¨ë¦¬ ì¶©ë¶„: {gpu_memory:.1f}GB VRAM")

        return True # ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ ì¶©ì¡±

    def initialize_pipeline(self) -> bool: # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” í•¨ìˆ˜ë¡œ ì´ë¦„ ë³€ê²½ (CogVideoX ì „ìš©)
        """CogVideoX-2b íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ë° GPU ë©”ëª¨ë¦¬ ìµœì í™”."""
        if not COGVIDEODX_AVAILABLE: # CogVideoX ì˜ì¡´ì„±ì´ ì—†ìœ¼ë©´ ì´ˆê¸°í™” ë¶ˆê°€
            print("âŒ CogVideoX-2b ê¸°ë³¸ ì˜ì¡´ì„±ì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”ê°€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
            return False

        if self.is_initialized: # ì´ë¯¸ ì´ˆê¸°í™”ë˜ì—ˆë‹¤ë©´ ë°”ë¡œ ë°˜í™˜
            return True

        if not torch.cuda.is_available(): # GPU ì—†ìœ¼ë©´ ê²½ê³ 
            print("âŒ GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CogVideoX-2bëŠ” GPU ì „ìš©ì…ë‹ˆë‹¤.")
            return False

        try:
            print(f"ğŸ”„ CogVideoX-2b GPU íŒŒì´í”„ë¼ì¸ ë¡œë”© ì¤‘... ({self.model_id})")
            torch.cuda.empty_cache() # GPU ë©”ëª¨ë¦¬ ìºì‹œ ë¹„ì›€

            self.pipeline = DiffusionPipeline.from_pretrained( # CogVideoX ëª¨ë¸ ë¡œë“œ
                self.model_id,
                torch_dtype=torch.float16, # ë¶€ë™ì†Œìˆ˜ì  16ë¹„íŠ¸ ì‚¬ìš© (ë©”ëª¨ë¦¬ ì ˆì•½)
                use_safetensors=True, # ì•ˆì „í•œ ê°€ì¤‘ì¹˜ íŒŒì¼ í˜•ì‹ ì‚¬ìš©
                trust_remote_code=True, # ì›ê²© ì½”ë“œ ì‹¤í–‰ í—ˆìš© (í•„ìš”í•œ ê²½ìš°)
            )
            device = torch.device("cuda") # ì¥ì¹˜ ì§€ì • (GPU)
            self.pipeline = self.pipeline.to(device) # íŒŒì´í”„ë¼ì¸ì„ GPUë¡œ ì´ë™

            # CogVideoX ì „ìš© GPU ë©”ëª¨ë¦¬ ìµœì í™”: ë‹¤ì–‘í•œ ë©”ëª¨ë¦¬ ì ˆì•½ ê¸°ë²• ì ìš©.
            print("ğŸ”§ CogVideoX ì „ìš© GPU ë©”ëª¨ë¦¬ ìµœì í™” ì ìš© ì¤‘...")
            try:
                if hasattr(self.pipeline, 'enable_vae_slicing'): # VAE ìŠ¬ë¼ì´ì‹± í™œì„±í™” (ë©”ëª¨ë¦¬ ì ˆì•½)
                    self.pipeline.enable_vae_slicing()
                    print("âœ… VAE ìŠ¬ë¼ì´ì‹± í™œì„±í™”")
                elif hasattr(self.pipeline, 'vae') and hasattr(self.pipeline.vae, 'enable_slicing'): # ëŒ€ì•ˆ VAE ìŠ¬ë¼ì´ì‹±
                    self.pipeline.vae.enable_slicing()
                    print("âœ… VAE ìŠ¬ë¼ì´ì‹± í™œì„±í™” (ëŒ€ì•ˆ ë°©ë²•)")
                else:
                    print("âš ï¸ VAE ìŠ¬ë¼ì´ì‹± ë¯¸ì§€ì› - ê±´ë„ˆëœ€")
            except Exception as vae_error:
                print(f"âš ï¸ VAE ìµœì í™” ì‹¤íŒ¨: {vae_error}")

            try:
                if hasattr(self.pipeline, 'enable_attention_slicing'): # ì–´í…ì…˜ ìŠ¬ë¼ì´ì‹± í™œì„±í™” (ë©”ëª¨ë¦¬ ì ˆì•½)
                    self.pipeline.enable_attention_slicing("max") # ìµœëŒ€ ì ˆì•½ ëª¨ë“œ
                    print("âœ… ì–´í…ì…˜ ìŠ¬ë¼ì´ì‹± í™œì„±í™” (ìµœëŒ€ ì ˆì•½ ëª¨ë“œ)")
                else:
                    print("âš ï¸ ì–´í…ì…˜ ìŠ¬ë¼ì´ì‹± ë¯¸ì§€ì› - ê±´ë„ˆëœ€")
            except Exception as attention_error:
                print(f"âš ï¸ ì–´í…ì…˜ ìµœì í™” ì‹¤íŒ¨: {attention_error}")

            try:
                if hasattr(self.pipeline, 'enable_model_cpu_offload'): # CPU ì˜¤í”„ë¡œë”© í™œì„±í™” (GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ)
                    self.pipeline.enable_model_cpu_offload()
                    print("âœ… CPU ì˜¤í”„ë¡œë”© í™œì„±í™” (GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ì ê·¹ í™œìš©)")
                else:
                    print("âš ï¸ CPU ì˜¤í”„ë¡œë”© ë¯¸ì§€ì›")
            except Exception as offload_error:
                print(f"âš ï¸ CPU ì˜¤í”„ë¡œë”© ì„¤ì • ì‹¤íŒ¨: {offload_error}")

            try:
                if hasattr(self.pipeline, 'enable_xformers_memory_efficient_attention'): # xFormers ìµœì í™” í™œì„±í™” (ì†ë„/ë©”ëª¨ë¦¬)
                    self.pipeline.enable_xformers_memory_efficient_attention()
                    print("âœ… xFormers ë©”ëª¨ë¦¬ íš¨ìœ¨ ì–´í…ì…˜ í™œì„±í™”")
                else:
                    print("âš ï¸ xFormers ë¯¸ì§€ì› - ê¸°ë³¸ ì–´í…ì…˜ ì‚¬ìš©")
            except Exception as xformers_error:
                print(f"âš ï¸ xFormers ìµœì í™” ì‹¤íŒ¨: {xformers_error}")

            self.is_initialized = True # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ í”Œë˜ê·¸

            if torch.cuda.is_available(): # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶œë ¥
                allocated = torch.cuda.memory_allocated() / (1024**3) # í• ë‹¹ëœ ë©”ëª¨ë¦¬ (GB)
                reserved = torch.cuda.memory_reserved() / (1024**3) # ì˜ˆì•½ëœ ë©”ëª¨ë¦¬ (GB)
                print(f"ğŸ“Š GPU ë©”ëª¨ë¦¬: í• ë‹¹ {allocated:.1f}GB, ì˜ˆì•½ {reserved:.1f}GB")

            print("âœ… CogVideoX-2b GPU íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
            return True

        except Exception as e: # ì´ˆê¸°í™” ì¤‘ ì—ëŸ¬ ë°œìƒ ì‹œ
            if "out of memory" in str(e).lower(): # ë©”ëª¨ë¦¬ ë¶€ì¡± ì—ëŸ¬ ì²˜ë¦¬
                print("âŒ ì´ˆê¸°í™” ì¤‘ GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ë°œìƒ! ë” ì ê·¹ì ì¸ ìµœì í™” ëª¨ë“œë¡œ ì¬ì‹œë„í•©ë‹ˆë‹¤.")
                print("ğŸ”§ í•´ê²°ë°©ë²•:") # í•´ê²° ë°©ë²• ì œì‹œ
                print("    1. ë‹¤ë¥¸ GPU í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
                print("    2. ì‹œìŠ¤í…œ ì¬ë¶€íŒ…")
                try: # ë©”ëª¨ë¦¬ ì ˆì•½ ëª¨ë“œë¡œ ì¬ì‹œë„
                    print("ğŸ”„ ë©”ëª¨ë¦¬ ì ˆì•½ ëª¨ë“œë¡œ ì¬ì‹œë„...")
                    torch.cuda.empty_cache() # ìºì‹œ ë¹„ìš°ê¸°

                    self.pipeline = DiffusionPipeline.from_pretrained( # ëª¨ë¸ ì¬ë¡œë“œ (ë©”ëª¨ë¦¬ ì ˆì•½ ì˜µì…˜ ì¶”ê°€)
                        self.model_id,
                        torch_dtype=torch.float16,
                        device_map=None, # ì¥ì¹˜ ë§µí•‘ ê°•ì œ í•´ì œ
                        local_files_only=False,
                        low_cpu_mem_usage=True, # ì¶”ê°€: ë‚®ì€ CPU ë©”ëª¨ë¦¬ ì‚¬ìš© ì˜µì…˜
                        trust_remote_code=True
                    )
                    self.pipeline = self.pipeline.to("cuda") # GPUë¡œ ì´ë™
                    # ë” ì ê·¹ì ì¸ ìµœì í™” ì¬ì ìš©
                    if hasattr(self.pipeline, 'enable_vae_slicing'):
                        self.pipeline.enable_vae_slicing()
                    if hasattr(self.pipeline, 'enable_attention_slicing'):
                        self.pipeline.enable_attention_slicing("max")
                    if hasattr(self.pipeline, 'enable_model_cpu_offload'):
                        self.pipeline.enable_model_cpu_offload()
                    if hasattr(self.pipeline, 'enable_xformers_memory_efficient_attention'):
                        try:
                            self.pipeline.enable_xformers_memory_efficient_attention()
                        except Exception:
                            pass
                    self.is_initialized = True # ì´ˆê¸°í™” ì™„ë£Œ
                    print("âœ… ë©”ëª¨ë¦¬ ì ˆì•½ ëª¨ë“œë¡œ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì„±ê³µ")
                    return True
                except Exception as retry_error: # ì¬ì‹œë„ ì‹¤íŒ¨
                    print(f"âŒ ë©”ëª¨ë¦¬ ì ˆì•½ ëª¨ë“œë¡œë„ ì´ˆê¸°í™” ì‹¤íŒ¨: {retry_error}")
                    return False
            elif "trust_remote_code" in str(e) or "Placeholder" in str(e): # ìºì‹œ/í† í¬ë‚˜ì´ì € ë¬¸ì œ ì²˜ë¦¬ (Diffusers ì˜¤ë¥˜)
                print("ğŸ”„ ìºì‹œ ë¬¸ì œë¡œ ì¸í•œ ê°•ì œ ì¬ë‹¤ìš´ë¡œë“œ ì‹œë„...")
                try: # ê°•ì œ ì¬ë‹¤ìš´ë¡œë“œ
                    self.pipeline = DiffusionPipeline.from_pretrained( # ëª¨ë¸ ê°•ì œ ì¬ë‹¤ìš´ë¡œë“œ
                        self.model_id,
                        torch_dtype=torch.float16,
                        device_map=None,
                        local_files_only=False,
                        use_safetensors=True,
                        trust_remote_code=True,
                        force_download=True, # ê°•ì œ ë‹¤ìš´ë¡œë“œ ì˜µì…˜
                        resume_download=True # ì´ì–´ì„œ ë‹¤ìš´ë¡œë“œ ì˜µì…˜
                    )
                    self.pipeline = self.pipeline.to("cuda") # GPUë¡œ ì´ë™
                    self.is_initialized = True # ì´ˆê¸°í™” ì™„ë£Œ
                    print("âœ… ê°•ì œ ì¬ë‹¤ìš´ë¡œë“œë¡œ ì´ˆê¸°í™” ì„±ê³µ")
                    return True
                except Exception as retry_error: # ê°•ì œ ì¬ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨
                    print(f"âŒ ê°•ì œ ì¬ë‹¤ìš´ë¡œë“œë„ ì‹¤íŒ¨: {retry_error}")
                    return False
            else: # ê¸°íƒ€ ì´ˆê¸°í™” ì‹¤íŒ¨
                print(f"âŒ CogVideoX-2b íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                print("ğŸ”§ ê°€ëŠ¥í•œ í•´ê²°ì±…:") # ê°€ëŠ¥í•œ í•´ê²°ì±… ì œì‹œ
                print("    1. transformers ì—…ë°ì´íŠ¸: pip install --upgrade transformers")
                print("    2. diffusers ì—…ë°ì´íŠ¸: pip install --upgrade diffusers")
                print("    3. HuggingFace ìºì‹œ ì‚­ì œ í›„ ì¬ì‹œë„")
                return False

    def initialize_riffusion_pipeline(self) -> bool:
        """Riffusion íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”: BGM ìƒì„±ì„ ìœ„í•œ ëª¨ë¸ ë¡œë“œ."""
        global RIFFUSION_PIPELINE_AVAILABLE # ì „ì—­ í”Œë˜ê·¸ë¥¼ ìˆ˜ì •í•  ìˆ˜ ìˆë„ë¡ global ì„ ì–¸

        if not RIFFUSION_PIPELINE_AVAILABLE: # ìƒë‹¨ì—ì„œ Diffusers ëª¨ë“ˆì´ ì•„ì˜ˆ ë¡œë“œë˜ì§€ ì•Šì•˜ë‹¤ë©´
            print("âŒ Diffusers ëª¨ë“ˆ ë˜ëŠ” Riffusion ì§€ì›ì´ ì—†ì–´ Riffusion BGM ê¸°ë³¸ ì˜ì¡´ì„±ì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False
        
        if self.riffusion_initialized: # ì´ë¯¸ ì´ˆê¸°í™”ë˜ì—ˆë‹¤ë©´ ë°”ë¡œ ë°˜í™˜
            return True

        if not torch.cuda.is_available(): # GPU ì—†ìœ¼ë©´ ê²½ê³  (Riffusionì€ GPU ê¶Œì¥)
            print("âŒ GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Riffusionì€ GPUê°€ ê¶Œì¥ë©ë‹ˆë‹¤.")
            RIFFUSION_PIPELINE_AVAILABLE = False # GPU ì—†ìœ¼ë©´ Riffusion ê¸°ëŠ¥ ë¹„í™œì„±í™”
            return False

        try:
            print(f"ğŸ”„ Riffusion GPU íŒŒì´í”„ë¼ì¸ ë¡œë”© ì¤‘... ({self.RIFFUSION_MODEL_ID})")
            torch.cuda.empty_cache() # GPU ë©”ëª¨ë¦¬ ìºì‹œ ë¹„ì›€

            self.riffusion_pipeline = DiffusionPipeline.from_pretrained( # Riffusion ëª¨ë¸ ë¡œë“œ (DiffusionPipeline ì‚¬ìš©)
                self.RIFFUSION_MODEL_ID,
                torch_dtype=torch.float16, # ë¶€ë™ì†Œìˆ˜ì  16ë¹„íŠ¸ ì‚¬ìš©
                use_safetensors=True, # ì•ˆì „í•œ ê°€ì¤‘ì¹˜ íŒŒì¼ í˜•ì‹ ì‚¬ìš©
                trust_remote_code=True, # Riffusion ëª¨ë¸ë„ custom codeë¥¼ í¬í•¨í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¶”ê°€
            )
            device = torch.device("cuda") # ì¥ì¹˜ ì§€ì • (GPU)
            self.riffusion_pipeline = self.riffusion_pipeline.to(device) # íŒŒì´í”„ë¼ì¸ì„ GPUë¡œ ì´ë™
            
            # Riffusion íŒŒì´í”„ë¼ì¸ ìµœì í™” (í•„ìš”ì‹œ)
            if hasattr(self.riffusion_pipeline, 'enable_xformers_memory_efficient_attention'): # xFormers ìµœì í™”
                try:
                    self.riffusion_pipeline.enable_xformers_memory_efficient_attention()
                    print("âœ… Riffusion xFormers ë©”ëª¨ë¦¬ íš¨ìœ¨ ì–´í…ì…˜ í™œì„±í™”")
                except Exception:
                    print("âš ï¸ Riffusion xFormers ë¯¸ì„¤ì¹˜ - ê¸°ë³¸ ì–´í…ì…˜ ì‚¬ìš©")
            if hasattr(self.riffusion_pipeline, 'enable_model_cpu_offload'): # CPU ì˜¤í”„ë¡œë”©
                self.riffusion_pipeline.enable_model_cpu_offload()
                print("âœ… Riffusion CPU ì˜¤í”„ë¡œë”© í™œì„±í™”")

            self.riffusion_initialized = True # Riffusion íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ í”Œë˜ê·¸
            print("âœ… Riffusion GPU íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
            return True

        except Exception as e: # Riffusion ì´ˆê¸°í™” ì‹¤íŒ¨
            print(f"âŒ Riffusion íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            print("ğŸ”§ ê°€ëŠ¥í•œ í•´ê²°ì±…:") # ê°€ëŠ¥í•œ í•´ê²°ì±… ì œì‹œ
            print("    1. diffusers ì—…ë°ì´íŠ¸: pip install --upgrade diffusers")
            print("    2. HuggingFace ìºì‹œ ì‚­ì œ í›„ ì¬ì‹œë„")
            return False

    async def generate_riffusion_bgm(self, prompt: str, duration: int) -> Optional[str]: # BGM ìƒì„± í•¨ìˆ˜ (ë¹„ë™ê¸°)
        """Riffusion ëª¨ë¸ë¡œ ë°°ê²½ ìŒì•… ìƒì„±: ì—¬ëŸ¬ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„± í›„ FFmpegìœ¼ë¡œ ë³‘í•©."""
        if not self.initialize_riffusion_pipeline(): # Riffusion íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹œë„
            return None # ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ None ë°˜í™˜

        global BGM_GENERATION_AVAILABLE # ì „ì—­ ë³€ìˆ˜ BGM_GENERATION_AVAILABLE ì‚¬ìš©
        if not BGM_GENERATION_AVAILABLE: # BGM ìƒì„± ë¶ˆê°€í•˜ë©´ ë°˜í™˜
            print("âŒ Riffusion íŒŒì´í”„ë¼ì¸ì´ ë¡œë“œë˜ì§€ ì•Šì•„ BGM ìƒì„±ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
            return None

        print(f"ğŸ¶ Riffusion BGM ìƒì„± ì‹œì‘ (í”„ë¡¬í”„íŠ¸: '{prompt}', ê¸¸ì´: {duration}ì´ˆ)")
        try:
            audio_segments_paths = [] # ìƒì„±ëœ ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            segment_duration_s = 5 # Riffusionì´ í•œ ë²ˆì— ìƒì„±í•˜ëŠ” ì˜¤ë””ì˜¤ ê¸¸ì´ (ì•½ 5ì´ˆ)
            num_segments_to_generate = math.ceil(duration / segment_duration_s) # í•„ìš”í•œ ì„¸ê·¸ë¨¼íŠ¸ ê°œìˆ˜ ê³„ì‚°

            for i in range(num_segments_to_generate): # í•„ìš”í•œ ë§Œí¼ ì„¸ê·¸ë¨¼íŠ¸ ë°˜ë³µ ìƒì„±
                print(f"    Riffusion ì„¸ê·¸ë¨¼íŠ¸ {i+1}/{num_segments_to_generate} ìƒì„± ì¤‘...")
                # Riffusion íŒŒì´í”„ë¼ì¸ í˜¸ì¶œ (ì˜¤ë””ì˜¤ ë°ì´í„° ë°˜í™˜)
                riff = self.riffusion_pipeline(prompt=prompt).audios[0] 
                
                segment_path = self.bgm_dir / f"riffusion_segment_{datetime.now().strftime('%Y%m%d%H%M%S')}_{i}.wav" # ì„¸ê·¸ë¨¼íŠ¸ íŒŒì¼ ê²½ë¡œ
                sf.write(str(segment_path), riff, samplerate=44100) # WAV íŒŒì¼ë¡œ ì €ì¥
                audio_segments_paths.append(str(segment_path))

            if len(audio_segments_paths) > 1: # ì—¬ëŸ¬ ì„¸ê·¸ë¨¼íŠ¸ê°€ ìƒì„±ë˜ë©´ FFmpegìœ¼ë¡œ ë³‘í•©
                combined_bgm_path = self.bgm_dir / f"riffusion_combined_{datetime.now().strftime('%Y%m%d%H%M%S')}.wav" # ìµœì¢… ë³‘í•© íŒŒì¼ ê²½ë¡œ
                concat_list_path = self.bgm_dir / f"concat_list_{datetime.now().strftime('%Y%m%d%H%M%S')}.txt" # FFmpeg concat ë¦¬ìŠ¤íŠ¸ íŒŒì¼

                with open(concat_list_path, "w") as f: # concat ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
                    for audio_seg_path in audio_segments_paths:
                        f.write(f"file '{Path(audio_seg_path).resolve()}'\n") # ê° ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œ ê¸°ë¡
                
                ffmpeg_cmd_concat = [ # FFmpeg concat ëª…ë ¹
                    "ffmpeg", "-y",
                    "-f", "concat", # concat demuxer ì‚¬ìš© (íŒŒì¼ ëª©ë¡ì„ ì…ë ¥ìœ¼ë¡œ ë°›ìŒ)
                    "-safe", "0", # ì•ˆì „ ëª¨ë“œ ë¹„í™œì„±í™” (í•„ìš”ì‹œ - ê²½ë¡œì— íŠ¹ìˆ˜ë¬¸ìê°€ ìˆì„ ê²½ìš°)
                    "-i", str(concat_list_path), # concat ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ì…ë ¥
                    "-c", "copy", # ìŠ¤íŠ¸ë¦¼ ë³µì‚¬ (ì¬ì¸ì½”ë”© ì—†ì´ ë¹ ë¥´ê²Œ ë³‘í•©)
                    str(combined_bgm_path) # ì¶œë ¥ íŒŒì¼
                ]
                
                subprocess.run(ffmpeg_cmd_concat, capture_output=True, text=True, check=True, timeout=180) # FFmpeg ì‹¤í–‰ ë° íƒ€ì„ì•„ì›ƒ
                
                for audio_seg_path in audio_segments_paths: # ì„ì‹œ ì„¸ê·¸ë¨¼íŠ¸ íŒŒì¼ ì‚­ì œ
                    os.remove(audio_seg_path)
                os.remove(concat_list_path) # concat ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ì‚­ì œ

                return str(combined_bgm_path) # ë³‘í•©ëœ BGM ê²½ë¡œ ë°˜í™˜
            else: # ì„¸ê·¸ë¨¼íŠ¸ê°€ í•˜ë‚˜ë¿ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
                return str(audio_segments_paths[0])
        except Exception as e: # BGM ìƒì„± ì‹¤íŒ¨ ì‹œ
            print(f"âŒ Riffusion BGM ìƒì„± ì‹¤íŒ¨: {e}")
            return None # ì‹¤íŒ¨ ì‹œ None ë°˜í™˜

    async def generate_video_from_prompt(self, # ë¹„ë””ì˜¤ ìƒì„± í•¨ìˆ˜ (ë¹„ë™ê¸°)
                                         prompt: str,
                                         duration: int = 30,
                                         quality: str = "balanced",
                                         enable_bgm: bool = False,
                                         bgm_prompt: Optional[str] = None) -> Optional[tuple[str, Optional[str]]]:
        """í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ CogVideoX-2b ë¹„ë””ì˜¤ ìƒì„± (BGM ì„ íƒì  ì¶”ê°€)."""
        if not COGVIDEODX_AVAILABLE: # CogVideoX ì‚¬ìš© ë¶ˆê°€í•˜ë©´ ì‹¤íŒ¨
            print("âŒ CogVideoX-2b ê¸°ë³¸ ì˜ì¡´ì„± ëˆ„ë½ìœ¼ë¡œ ë¹„ë””ì˜¤ ìƒì„±ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
            return None, None

        if not self.initialize_pipeline(): # CogVideoX íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹œë„
            return None, None # ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ None ë°˜í™˜

        if TORCH_AVAILABLE: # GPU ë©”ëª¨ë¦¬ ì •ë¦¬ (íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì „)
            import gc
            if torch.cuda.is_available():
                torch.cuda.empty_cache() # CUDA ìºì‹œ ë¹„ìš°ê¸°
                torch.cuda.synchronize() # GPU ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
            gc.collect() # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì‹¤í–‰

        generation_params = self._get_quality_params_cogvideox(quality) # í’ˆì§ˆì— ë”°ë¥¸ ìƒì„± íŒŒë¼ë¯¸í„° ì„¤ì •

        base_fps = 8 # ê¸°ë³¸ FPS (ì´ˆë‹¹ í”„ë ˆì„ ìˆ˜)
        num_frames = int(duration * base_fps) # ì´ í”„ë ˆì„ ìˆ˜ ê³„ì‚°
        if num_frames < 16: # ìµœì†Œ í”„ë ˆì„ ìˆ˜ ì œí•œ (ë„ˆë¬´ ì§§ì€ ì˜ìƒ ë°©ì§€)
            num_frames = 16
            print(f"âš ï¸ ìš”ì²­ëœ ê¸¸ì´ì— ë¹„í•´ í”„ë ˆì„ ìˆ˜ê°€ ë„ˆë¬´ ì ì–´ {num_frames}í”„ë ˆì„ìœ¼ë¡œ ì¡°ì •ë©ë‹ˆë‹¤.")

        actual_expected_duration = num_frames / base_fps # ì‹¤ì œ ìƒì„±ë  ì˜ˆìƒ ë¹„ë””ì˜¤ ê¸¸ì´ (ì¡°ì •ëœ í”„ë ˆì„ ìˆ˜ ê¸°ì¤€)

        print(f"ğŸ¬ CogVideoX-2b ë¹„ë””ì˜¤ ìƒì„± ì‹œì‘ (í”„ë¡¬í”„íŠ¸: '{prompt}')") # ì‹œì‘ ë©”ì‹œì§€
        print(f"ğŸ“‹ ì„¤ì •: {generation_params['num_inference_steps']}ë‹¨ê³„, {num_frames}í”„ë ˆì„, {base_fps}fps, ì˜ˆìƒ ê¸¸ì´: {actual_expected_duration:.1f}ì´ˆ")

        try:
            generator = torch.Generator(device="cuda").manual_seed(42) # GPUìš© ë‚œìˆ˜ ìƒì„±ê¸° (ê²°ê³¼ ì¬í˜„ì„± ìœ„í•¨)

            video_frames = self.pipeline( # CogVideoX íŒŒì´í”„ë¼ì¸ í˜¸ì¶œ (ë¹„ë””ì˜¤ í”„ë ˆì„ ìƒì„±)
                prompt=prompt, # í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸
                num_inference_steps=generation_params['num_inference_steps'], # ì¶”ë¡  ë‹¨ê³„ ìˆ˜
                guidance_scale=generation_params['guidance_scale'], # ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼ (ìƒì„± í’ˆì§ˆ/í”„ë¡¬í”„íŠ¸ ì¼ì¹˜ë„)
                width=generation_params['width'], # ë¹„ë””ì˜¤ ë„ˆë¹„
                height=generation_params['height'], # ë¹„ë””ì˜¤ ë†’ì´
                num_frames=num_frames, # ìƒì„±í•  í”„ë ˆì„ ìˆ˜
                generator=generator, # ë‚œìˆ˜ ìƒì„±ê¸°
            ).frames # ìƒì„±ëœ ë¹„ë””ì˜¤ í”„ë ˆì„ (ë¦¬ìŠ¤íŠ¸ í˜•íƒœ)

            if TORCH_AVAILABLE and torch.cuda.is_available(): # GPU ë©”ëª¨ë¦¬ ì¬ì •ë¦¬ (ìƒì„± í›„)
                torch.cuda.empty_cache()
                torch.cuda.synchronize()

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S") # íŒŒì¼ëª…ìš© íƒ€ì„ìŠ¤íƒ¬í”„
            output_video_path = self.output_dir / f"cogvideox_generated_{int(actual_expected_duration)}s_{timestamp}.mp4" # ì¶œë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ

            # ğŸ”§ ìˆ˜ì •ëœ ë¹„ë””ì˜¤ ì €ì¥ ë¶€ë¶„ (ë¦¬ìŠ¤íŠ¸ í”„ë ˆì„ ì²˜ë¦¬)
            try:
                # CogVideoX ì¶œë ¥ ë°ì´í„° êµ¬ì¡° ë¶„ì„
                print(f"ğŸ” ë¹„ë””ì˜¤ í”„ë ˆì„ íƒ€ì…: {type(video_frames)}")
                
                if isinstance(video_frames, list):
                    print(f"ğŸ” ë¦¬ìŠ¤íŠ¸ ê¸¸ì´: {len(video_frames)}")
                    if len(video_frames) > 0:
                        print(f"ğŸ” ì²« ë²ˆì§¸ ìš”ì†Œ íƒ€ì…: {type(video_frames[0])}")
                        if hasattr(video_frames[0], 'shape'):
                            print(f"ğŸ” ì²« ë²ˆì§¸ ìš”ì†Œ í˜•íƒœ: {video_frames[0].shape}")
                    
                    # ë¦¬ìŠ¤íŠ¸ì—ì„œ ì‹¤ì œ í”„ë ˆì„ ë°°ì—´ ì¶”ì¶œ
                    if len(video_frames) > 0:
                        # ì²« ë²ˆì§¸ ìš”ì†Œê°€ ì‹¤ì œ í”„ë ˆì„ ë°°ì—´ì¸ ê²½ìš°
                        frames_data = video_frames[0]
                    else:
                        raise Exception("ë¹„ë””ì˜¤ í”„ë ˆì„ ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                else:
                    frames_data = video_frames
                
                # PyTorch í…ì„œë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
                if hasattr(frames_data, 'cpu'):
                    # PyTorch í…ì„œì¸ ê²½ìš°
                    video_frames_np = frames_data.cpu().numpy()
                    print("ğŸ”„ PyTorch í…ì„œë¥¼ numpyë¡œ ë³€í™˜")
                elif hasattr(frames_data, 'numpy'):
                    # GPU ë°°ì—´ì¸ ê²½ìš°
                    video_frames_np = frames_data.numpy()
                    print("ğŸ”„ GPU ë°°ì—´ì„ numpyë¡œ ë³€í™˜")
                else:
                    # ì´ë¯¸ numpyì´ê±°ë‚˜ ë‹¤ë¥¸ í˜•íƒœ
                    video_frames_np = frames_data
                    print("ğŸ”„ ê¸°ì¡´ ë°ì´í„° ì‚¬ìš©")
                
                # ìµœì¢… ë°ì´í„° íƒ€ì…ê³¼ í˜•íƒœ í™•ì¸
                print(f"ğŸ” ìµœì¢… í”„ë ˆì„ íƒ€ì…: {type(video_frames_np)}")
                if hasattr(video_frames_np, 'shape'):
                    print(f"ğŸ” ìµœì¢… í”„ë ˆì„ í˜•íƒœ: {video_frames_np.shape}")
                    print(f"ğŸ” ìµœì¢… í”„ë ˆì„ ë°ì´í„° íƒ€ì…: {video_frames_np.dtype}")
                
                # export_to_video í•¨ìˆ˜ í˜¸ì¶œ
                export_to_video(video_frames_np, str(output_video_path), fps=base_fps)
                print("âœ… export_to_videoë¡œ ë¹„ë””ì˜¤ ì €ì¥ ì„±ê³µ")
                
            except Exception as export_error:
                print(f"âŒ export_to_video ì‹¤íŒ¨: {export_error}")
                print("ğŸ”„ ëŒ€ì²´ ë°©ë²•ìœ¼ë¡œ ë¹„ë””ì˜¤ ì €ì¥ ì‹œë„...")
                
                # ëŒ€ì²´ ë°©ë²•: imageioë¥¼ ì§ì ‘ ì‚¬ìš©
                try:
                    import imageio
                    import numpy as np
                    
                    # í”„ë ˆì„ ë°ì´í„° ì¶”ì¶œ ë° ë³€í™˜
                    if isinstance(video_frames, list) and len(video_frames) > 0:
                        frames_data = video_frames[0]  # ë¦¬ìŠ¤íŠ¸ì˜ ì²« ë²ˆì§¸ ìš”ì†Œ
                    else:
                        frames_data = video_frames
                    
                    # PyTorch í…ì„œë¥¼ numpyë¡œ ë³€í™˜
                    if hasattr(frames_data, 'cpu'):
                        frames = frames_data.cpu().numpy()
                    elif hasattr(frames_data, 'numpy'):
                        frames = frames_data.numpy()
                    else:
                        frames = np.array(frames_data)
                    
                    print(f"ğŸ” ëŒ€ì²´ ë°©ë²• - ì›ë³¸ í”„ë ˆì„ í˜•íƒœ: {frames.shape}, íƒ€ì…: {frames.dtype}")
                    
                    # ë°ì´í„° íƒ€ì… ì •ê·œí™”
                    if frames.dtype == np.float32 or frames.dtype == np.float64:
                        if frames.max() <= 1.0:
                            # 0-1 ë²”ìœ„ë¥¼ 0-255ë¡œ ë³€í™˜
                            frames = (frames * 255).astype(np.uint8)
                            print("ğŸ”„ float [0-1] ë²”ìœ„ë¥¼ uint8 [0-255]ë¡œ ë³€í™˜")
                        else:
                            # ì´ë¯¸ 0-255 ë²”ìœ„ì¸ float
                            frames = frames.astype(np.uint8)
                            print("ğŸ”„ floatì„ uint8ë¡œ ë³€í™˜")
                    elif frames.dtype != np.uint8:
                        # ê¸°íƒ€ ì •ìˆ˜ íƒ€ì…ì„ uint8ë¡œ ë³€í™˜
                        frames = frames.astype(np.uint8)
                        print(f"ğŸ”„ {frames.dtype}ì„ uint8ë¡œ ë³€í™˜")
                    
                    # ì°¨ì› ì¡°ì •
                    if len(frames.shape) == 5:
                        # (batch, frames, height, width, channels) -> (frames, height, width, channels)
                        frames = frames[0]
                        print("ğŸ”„ ë°°ì¹˜ ì°¨ì› ì œê±°: (B,F,H,W,C) -> (F,H,W,C)")
                    elif len(frames.shape) == 4:
                        # (frames, height, width, channels) - ì´ë¯¸ ì˜¬ë°”ë¥¸ í˜•íƒœ
                        print("âœ… ì˜¬ë°”ë¥¸ ì°¨ì›: (F,H,W,C)")
                    else:
                        print(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ì°¨ì›: {frames.shape}")
                    
                    print(f"ğŸ” ìµœì¢… í”„ë ˆì„ í˜•íƒœ: {frames.shape}, íƒ€ì…: {frames.dtype}")
                    
                    # imageioë¡œ ë¹„ë””ì˜¤ ì €ì¥
                    print("ğŸ¬ imageioë¡œ ë¹„ë””ì˜¤ ì €ì¥ ì¤‘...")
                    with imageio.get_writer(str(output_video_path), mode='I', fps=base_fps, codec='libx264', quality=8) as writer:
                        for i, frame in enumerate(frames):
                            if i % 10 == 0:  # ì§„í–‰ìƒí™© ì¶œë ¥
                                print(f"  í”„ë ˆì„ {i+1}/{len(frames)} ì €ì¥ ì¤‘...")
                            writer.append_data(frame)
                    
                    print(f"âœ… ëŒ€ì²´ ë°©ë²•ìœ¼ë¡œ ë¹„ë””ì˜¤ ì €ì¥ ì„±ê³µ: {output_video_path}")
                    
                except Exception as fallback_error:
                    print(f"âŒ ëŒ€ì²´ ë¹„ë””ì˜¤ ì €ì¥ë„ ì‹¤íŒ¨: {fallback_error}")
                    
                    # ë§ˆì§€ë§‰ ìˆ˜ë‹¨: ê° í”„ë ˆì„ì„ ì´ë¯¸ì§€ë¡œ ì €ì¥í•˜ê³  ffmpegë¡œ í•©ì„±
                    try:
                        print("ğŸ”„ ë§ˆì§€ë§‰ ìˆ˜ë‹¨: í”„ë ˆì„ë³„ ì´ë¯¸ì§€ ì €ì¥ í›„ ffmpeg í•©ì„±...")
                        
                        # ì„ì‹œ í”„ë ˆì„ ë””ë ‰í† ë¦¬ ìƒì„±
                        frames_dir = self.output_dir / f"temp_frames_{timestamp}"
                        frames_dir.mkdir(exist_ok=True)
                        
                        # í”„ë ˆì„ ë°ì´í„° ì¶”ì¶œ
                        if isinstance(video_frames, list) and len(video_frames) > 0:
                            frames_data = video_frames[0]
                        else:
                            frames_data = video_frames
                            
                        if hasattr(frames_data, 'cpu'):
                            frames = frames_data.cpu().numpy()
                        elif hasattr(frames_data, 'numpy'):
                            frames = frames_data.numpy()
                        else:
                            frames = np.array(frames_data)
                        
                        # ì°¨ì› ë° íƒ€ì… ì¡°ì •
                        if len(frames.shape) == 5:
                            frames = frames[0]
                        
                        if frames.dtype != np.uint8:
                            if frames.max() <= 1.0:
                                frames = (frames * 255).astype(np.uint8)
                            else:
                                frames = frames.astype(np.uint8)
                        
                        # ê° í”„ë ˆì„ì„ PNG ì´ë¯¸ì§€ë¡œ ì €ì¥
                        frame_paths = []
                        for i, frame in enumerate(frames):
                            frame_path = frames_dir / f"frame_{i:04d}.png"
                            imageio.imwrite(str(frame_path), frame)
                            frame_paths.append(str(frame_path))
                        
                        print(f"ğŸ“ {len(frame_paths)}ê°œ í”„ë ˆì„ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ")
                        
                        # ffmpegë¡œ ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ë¥¼ ë¹„ë””ì˜¤ë¡œ ë³€í™˜
                        ffmpeg_cmd = [
                            "ffmpeg", "-y",
                            "-framerate", str(base_fps),
                            "-i", str(frames_dir / "frame_%04d.png"),
                            "-c:v", "libx264",
                            "-pix_fmt", "yuv420p",
                            "-crf", "23",
                            str(output_video_path)
                        ]
                        
                        subprocess.run(ffmpeg_cmd, capture_output=True, text=True, check=True, timeout=300)
                        
                        # ì„ì‹œ í”„ë ˆì„ íŒŒì¼ë“¤ ì‚­ì œ
                        shutil.rmtree(str(frames_dir))
                        
                        print(f"âœ… ffmpeg í•©ì„±ìœ¼ë¡œ ë¹„ë””ì˜¤ ì €ì¥ ì„±ê³µ: {output_video_path}")
                        
                    except Exception as final_error:
                        print(f"âŒ ëª¨ë“  ë¹„ë””ì˜¤ ì €ì¥ ë°©ë²• ì‹¤íŒ¨: {final_error}")
                        raise Exception(f"ë¹„ë””ì˜¤ ì €ì¥ ì™„ì „ ì‹¤íŒ¨ - export_to_video: {export_error}, imageio: {fallback_error}, ffmpeg: {final_error}")

            file_size = output_video_path.stat().st_size / (1024*1024) # íŒŒì¼ í¬ê¸° (MB)
            actual_frames = len(video_frames) # ì‹¤ì œ ìƒì„±ëœ í”„ë ˆì„ ìˆ˜
            actual_duration = actual_frames / base_fps # ì‹¤ì œ ìƒì„±ëœ ë¹„ë””ì˜¤ ê¸¸ì´

            print(f"âœ… CogVideoX-2b ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {output_video_path}") # ì„±ê³µ ë©”ì‹œì§€
            print(f"ğŸ“Š ê²°ê³¼: {actual_frames}í”„ë ˆì„, {actual_duration:.1f}ì´ˆ, {file_size:.1f}MB")

            bgm_output_path = None # BGM ì¶œë ¥ ê²½ë¡œ ì´ˆê¸°í™”
            if enable_bgm and BGM_GENERATION_AVAILABLE: # BGM í™œì„±í™” ë° ê°€ìš©ì„± ì²´í¬
                actual_bgm_prompt = bgm_prompt if bgm_prompt else prompt # BGM í”„ë¡¬í”„íŠ¸ ê²°ì • (ëª…ì‹œëœ í”„ë¡¬í”„íŠ¸ ë˜ëŠ” ë¹„ë””ì˜¤ í”„ë¡¬í”„íŠ¸)
                bgm_output_path = await self.generate_riffusion_bgm(actual_bgm_prompt, duration) # BGM ìƒì„± (await í•„ìš”)
                
                if not bgm_output_path: # BGM ìƒì„± ì‹¤íŒ¨ ì‹œ
                    print("âš ï¸ Riffusion BGM ìƒì„± ì‹¤íŒ¨. BGM ì—†ì´ ìµœì¢… ì˜ìƒ í•©ì„±.")
            else: # BGM ë¹„í™œì„±í™” ë˜ëŠ” Riffusion ë¶ˆê°€ ì‹œ
                print("âš ï¸ ë°°ê²½ ìŒì•… ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì—ˆê±°ë‚˜ Riffusionì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")

            return str(output_video_path), bgm_output_path # ë¹„ë””ì˜¤ ê²½ë¡œì™€ BGM ê²½ë¡œ ë°˜í™˜ (íŠœí”Œ)

        except Exception as e: # ë¹„ë””ì˜¤ ìƒì„± ì¤‘ ì˜ˆì™¸ ì²˜ë¦¬
            print(f"âŒ CogVideoX-2b ë¹„ë””ì˜¤ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            raise # ì˜ˆì™¸ ë‹¤ì‹œ ë°œìƒ (í˜¸ì¶œìì—ê²Œ ì „ë‹¬)

    def _get_quality_params_cogvideox(self, quality: str) -> Dict:
        """RTX 4070ì— ìµœì í™”ëœ CogVideoX-2b ìƒì„± íŒŒë¼ë¯¸í„° (í’ˆì§ˆë³„ ì„¤ì •)."""
        quality_configs = { # í’ˆì§ˆë³„ (fast, balanced, high) ì„¤ì •
            "fast": { # ë¹ ë¥¸ ìƒì„± (ë‚®ì€ í’ˆì§ˆ, ì ì€ ë©”ëª¨ë¦¬)
                "num_inference_steps": 20, # ì¶”ë¡  ë‹¨ê³„ ìˆ˜
                "guidance_scale": 7.0, # ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼
                "width": 320, # ë„ˆë¹„
                "height": 320 # ë†’ì´
            },
            "balanced": { # ê· í˜• ì¡íŒ ìƒì„±
                "num_inference_steps": 30,
                "guidance_scale": 9.0,
                "width": 384,
                "height": 384
            },
            "high": { # ê³ í’ˆì§ˆ ìƒì„± (ë†’ì€ ë©”ëª¨ë¦¬)
                "num_inference_steps": 40,
                "guidance_scale": 11.0,
                "width": 448,
                "height": 448
            }
        }
        
        config = quality_configs.get(quality, quality_configs["fast"]) # ì„ íƒ í’ˆì§ˆ ì—†ìœ¼ë©´ 'fast' ê¸°ë³¸ ì ìš©
        print(f"ğŸ¥ CogVideoX-2b ì„¤ì •: '{quality}' í’ˆì§ˆ, {config['num_inference_steps']}ë‹¨ê³„, {config['width']}x{config['height']}")
        return config # ì„¤ì • ë°˜í™˜

# ê°„ë‹¨í•œ CogVideoX-2b ê´‘ê³  ë¹„ë””ì˜¤ ìƒì„± í•¨ìˆ˜ (ë…ë¦½í˜•): ì‹¤ì œ Generator í´ë˜ìŠ¤ë¥¼ í™œìš©í•˜ëŠ” í—¬í¼ í•¨ìˆ˜.
async def generate_ad_video_cogvideox(prompt: str, duration: int = 30, quality: str = "balanced", enable_bgm: bool = False, bgm_prompt: Optional[str] = None) -> Optional[tuple[str, Optional[str]]]:
    """ê°„ë‹¨í•œ CogVideoX-2b ê´‘ê³  ë¹„ë””ì˜¤ ìƒì„± í•¨ìˆ˜ (BGM ì„ íƒì  í™œì„±í™”)."""
    if not COGVIDEODX_AVAILABLE: # CogVideoX ì‚¬ìš© ë¶ˆê°€í•˜ë©´ ìŠ¤í‚µ
        print("âŒ CogVideoX-2b ê¸°ë³¸ ì˜ì¡´ì„±ì´ ì™„ì „í•˜ì§€ ì•Šì•„ ë¹„ë””ì˜¤ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return None, None # ë¹„ë””ì˜¤ ë° BGM ê²½ë¡œ ëª¨ë‘ None ë°˜í™˜
    
    if enable_bgm and not BGM_GENERATION_AVAILABLE: # BGM í™œì„±í™”ì¸ë° Riffusion ë¶ˆê°€í•˜ë©´ ê²½ê³ 
        print("âš ï¸ Riffusion BGM ê¸°ëŠ¥ì´ í™œì„±í™”ë˜ì—ˆì§€ë§Œ RiffusionPipeline ë˜ëŠ” SoundFileì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. BGM ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.")
        enable_bgm = False # BGM ë¹„í™œì„±í™” (BGM ìƒì„±ì´ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ)

    generator = CogVideoXGenerator() # CogVideoXGenerator ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    video_path, generated_bgm_path = await generator.generate_video_from_prompt(prompt, duration=duration, quality=quality, enable_bgm=enable_bgm, bgm_prompt=bgm_prompt) # ë¹„ë””ì˜¤ ìƒì„± ì‹¤í–‰ (await í•„ìš”)
    
    return video_path, generated_bgm_path # ë¹„ë””ì˜¤ ê²½ë¡œì™€ BGM ê²½ë¡œ ë°˜í™˜