# app/core/mock_openai_client.py - MusicGen ëŒ€ì•ˆ (ë” ì•ˆì •ì )

import os
import time
import torch
import numpy as np
import soundfile as sf
from dotenv import load_dotenv
from typing import List, Dict, Any

# ìŒì•… ìƒì„± ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‹œë„ (ìˆœì„œëŒ€ë¡œ)
MUSIC_GENERATOR_TYPE = None

try:
    # 1ì°¨ ì‹œë„: MusicGen (Meta - ë§¤ìš° ì•ˆì •ì )
    from transformers import AutoProcessor, MusicgenForConditionalGeneration
    MUSIC_GENERATOR_TYPE = "musicgen"
    print("ğŸµ MusicGen (Meta) ê°ì§€ - ì•ˆì •ì ì¸ ìŒì•… ìƒì„±")
except ImportError:
    try:
        # 2ì°¨ ì‹œë„: Riffusion (ë¬¸ì œê°€ í•´ê²°ëœ ê²½ìš°)
        from diffusers import StableDiffusionPipeline
        import riffusion
        # ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜ê°€ ìˆëŠ”ì§€ í™•ì¸
        if hasattr(riffusion, 'RiffusionPipeline') or len([attr for attr in dir(riffusion) if not attr.startswith('_')]) > 0:
            MUSIC_GENERATOR_TYPE = "riffusion"
            print("ğŸµ Riffusion ê°ì§€")
        else:
            raise ImportError("Riffusion ëª¨ë“ˆì´ ë¹„ì–´ìˆìŒ")
    except ImportError:
        # 3ì°¨ ì‹œë„: ê¸°ë³¸ ìŒì„± í•©ì„±ìœ¼ë¡œ ëŒ€ì²´
        MUSIC_GENERATOR_TYPE = "basic"
        print("ğŸµ ê¸°ë³¸ ìŒì„± í•©ì„± ì‚¬ìš© (Riffusion/MusicGen ë¶ˆê°€)")

load_dotenv()

class MockOpenAIClient:
    """ë‹¤ì–‘í•œ ìŒì•… ìƒì„± ì—”ì§„ì„ ì§€ì›í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self):
        print("âœ… Mock OpenAI client initialized")
        print(f"ğŸ­ ìŒì•… ìƒì„±: {MUSIC_GENERATOR_TYPE.upper()} ì—”ì§„ ì‚¬ìš©")
        
        # ìŒì•… ìƒì„± ëª¨ë¸ì€ í•„ìš”í•  ë•Œ ë¡œë“œ
        self.music_generator = None
        self.music_processor = None
    
    def _init_music_generator(self):
        """ìŒì•… ìƒì„± ëª¨ë¸ ì´ˆê¸°í™”"""
        if self.music_generator is None:
            if MUSIC_GENERATOR_TYPE == "musicgen":
                self._init_musicgen()
            elif MUSIC_GENERATOR_TYPE == "riffusion":
                self._init_riffusion()
            else:
                self._init_basic_audio()
    
    def _init_musicgen(self):
        """MusicGen ì´ˆê¸°í™” (Meta)"""
        try:
            print("ğŸµ MusicGen ëª¨ë¸ ë¡œë”© ì¤‘...")
            
            # MusicGen small ëª¨ë¸ ë¡œë“œ (ë¹ ë¥´ê³  ì•ˆì •ì )
            self.music_processor = AutoProcessor.from_pretrained("facebook/musicgen-small")
            self.music_generator = MusicgenForConditionalGeneration.from_pretrained("facebook/musicgen-small")
            
            # CPU/GPU ìë™ ì„ íƒ
            device = "cuda" if torch.cuda.is_available() else "cpu"
            self.music_generator = self.music_generator.to(device)
            
            print(f"âœ… MusicGen ë¡œë”© ì™„ë£Œ! (ë””ë°”ì´ìŠ¤: {device})")
            
        except Exception as e:
            print(f"âŒ MusicGen ë¡œë”© ì‹¤íŒ¨: {e}")
            self.music_generator = False
    
    def _init_riffusion(self):
        """Riffusion ì´ˆê¸°í™” (ë§Œì•½ ì‘ë™í•œë‹¤ë©´)"""
        try:
            print("ğŸµ Riffusion ëª¨ë¸ ë¡œë”© ì¤‘...")
            # Riffusion ì½”ë“œ (ì´ì „ê³¼ ë™ì¼)
            self.music_generator = True
            print("âœ… Riffusion ë¡œë”© ì™„ë£Œ!")
        except Exception as e:
            print(f"âŒ Riffusion ë¡œë”© ì‹¤íŒ¨: {e}")
            self.music_generator = False
    
    def _init_basic_audio(self):
        """ê¸°ë³¸ ì˜¤ë””ì˜¤ í•©ì„± ì´ˆê¸°í™”"""
        print("ğŸµ ê¸°ë³¸ ì˜¤ë””ì˜¤ í•©ì„± ì—”ì§„ ì´ˆê¸°í™”...")
        self.music_generator = True
        print("âœ… ê¸°ë³¸ ì˜¤ë””ì˜¤ í•©ì„± ì¤€ë¹„ ì™„ë£Œ!")

    def generate_concept(self, brand: str, keywords: str) -> str:
        """ê´‘ê³  ì»¨ì…‰ ìƒì„±"""
        print(f"ğŸ¨ ê´‘ê³  ì»¨ì…‰ ìƒì„±: {brand} + {keywords}")
        time.sleep(1)
        
        concept = f"""
ğŸ¯ {brand} Advertisement Concept

Main Message: "Experience the magic of {brand}"

Scene Breakdown:
1. Opening (0-10s): Cozy atmosphere with {keywords}
2. Product Focus (10-20s): Featured items and happy customers  
3. Closing (20-30s): Brand logo with memorable tagline

Narration: "When you need comfort, {brand} is here for you."

Visual Style: Warm colors, natural lighting, emotional connections
Keywords Integration: {keywords}
Target Emotion: Warmth, comfort, reliability
Call-to-Action: Visit your nearest {brand} location
"""
        print("âœ… ì»¨ì…‰ ìƒì„± ì™„ë£Œ")
        return concept

    def generate_images(self, concept: str, count: int = 3) -> List[Dict[str, Any]]:
        """ì´ë¯¸ì§€ ìƒì„± (ëª©ì—…)"""
        print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ {count}ê°œ ìƒì„± ì¤‘...")
        time.sleep(2)
        
        images = []
        scenes = [
            "cozy winter cafÃ© opening scene", 
            "featured products with happy customers",
            "brand logo closing with warm lighting"
        ]
        
        for i in range(count):
            scene = scenes[i] if i < len(scenes) else f"commercial scene {i+1}"
            images.append({
                "scene": scene,
                "image_path": f"data/temp/image_{i+1}.png",
                "prompt": f"Commercial advertisement: {scene}",
                "style": "professional photography, warm lighting"
            })
        
        print(f"âœ… ì´ë¯¸ì§€ {count}ê°œ ìƒì„± ì™„ë£Œ")
        return images
    
    def generate_voice(self, concept: str, text: str = None) -> List[Dict[str, Any]]:
        """ìŒì„± ë‚˜ë ˆì´ì…˜ ìƒì„± (ëª©ì—…)"""
        print("ğŸ¤ ìŒì„± ë‚˜ë ˆì´ì…˜ ìƒì„± ì¤‘...")
        time.sleep(1.5)
        
        if not text:
            if "Narration:" in concept:
                text = concept.split("Narration:")[1].split("\n")[0].strip().strip('"')
            else:
                text = "Experience the warmth and comfort that awaits you."
        
        voices = [{
            "voice_path": "data/temp/narration.wav",
            "text": text,
            "duration": len(text.split()) * 0.5,
            "voice_style": "professional, warm, inviting",
            "language": "en-US"
        }]
        
        print("âœ… ìŒì„± ë‚˜ë ˆì´ì…˜ ìƒì„± ì™„ë£Œ")
        return voices

    def generate_music(self, concept: str, keywords: str = "", count: int = 3) -> List[Dict[str, Any]]:
        """ë°°ê²½ìŒì•… ìƒì„± - ë‹¤ì¤‘ ì—”ì§„ ì§€ì›"""
        print(f"ğŸµ ë°°ê²½ìŒì•… ìƒì„± ì‹œì‘... (ì—”ì§„: {MUSIC_GENERATOR_TYPE.upper()})")
        
        # ìŒì•… ìƒì„± ëª¨ë¸ ì´ˆê¸°í™”
        self._init_music_generator()
        
        if not self.music_generator:
            print("âš ï¸ ëª¨ë“  ìŒì•… ìƒì„± ì—”ì§„ ì‚¬ìš© ë¶ˆê°€, ëª©ì—… ë°ì´í„° ë°˜í™˜")
            return self._generate_mock_music()
        
        try:
            # ì»¨ì…‰ ë¶„ì„
            brand_style = self._analyze_music_style(concept, keywords)
            
            # ì„¹ì…˜ë³„ ìŒì•… ìƒì„±
            music_sections = [
                {
                    "name": "opening",
                    "prompt": f"{brand_style['style']} {brand_style['mood']} commercial intro",
                    "duration": 8.0
                },
                {
                    "name": "main", 
                    "prompt": f"{brand_style['style']} {brand_style['mood']} background music",
                    "duration": 15.0
                },
                {
                    "name": "closing",
                    "prompt": f"{brand_style['mood']} memorable ending theme",
                    "duration": 5.0
                }
            ]
            
            generated_music = []
            
            for section in music_sections:
                try:
                    # ì—”ì§„ë³„ ìŒì•… ìƒì„±
                    if MUSIC_GENERATOR_TYPE == "musicgen":
                        filepath = self._generate_music_with_musicgen(
                            prompt=section["prompt"],
                            duration=section["duration"]
                        )
                    elif MUSIC_GENERATOR_TYPE == "riffusion":
                        filepath = self._generate_music_with_riffusion(
                            prompt=section["prompt"],
                            duration=section["duration"]
                        )
                    else:
                        filepath = self._generate_music_with_basic_audio(
                            prompt=section["prompt"],
                            duration=section["duration"]
                        )
                    
                    generated_music.append({
                        "section": section["name"],
                        "file_path": filepath,
                        "duration": section["duration"],
                        "prompt": section["prompt"],
                        "style": brand_style,
                        "engine": MUSIC_GENERATOR_TYPE
                    })
                    
                except Exception as e:
                    print(f"âŒ {section['name']} ìŒì•… ìƒì„± ì‹¤íŒ¨: {e}")
                    # ëª©ì—…ìœ¼ë¡œ ëŒ€ì²´
                    generated_music.append({
                        "section": section["name"],
                        "file_path": f"data/temp/{section['name']}_music.wav",
                        "duration": section["duration"],
                        "prompt": section["prompt"],
                        "style": brand_style,
                        "engine": "mock"
                    })
            
            print(f"âœ… ë°°ê²½ìŒì•… {len(generated_music)}ê°œ ìƒì„± ì™„ë£Œ ({MUSIC_GENERATOR_TYPE.upper()})")
            return generated_music
            
        except Exception as e:
            print(f"âŒ ë°°ê²½ìŒì•… ìƒì„± ì‹¤íŒ¨: {e}")
            return self._generate_mock_music()

    def _analyze_music_style(self, concept: str, keywords: str) -> Dict[str, str]:
        """ì»¨ì…‰ê³¼ í‚¤ì›Œë“œì—ì„œ ìŒì•… ìŠ¤íƒ€ì¼ ë¶„ì„"""
        concept_lower = concept.lower()
        keywords_lower = keywords.lower()
        
        if "starbucks" in concept_lower:
            brand = "starbucks"
        elif "cafÃ©" in concept_lower or "coffee" in concept_lower:
            brand = "cafÃ©"
        else:
            brand = "commercial"
        
        if any(word in concept_lower or word in keywords_lower 
               for word in ["winter", "ê²¨ìš¸", "cozy", "warm"]):
            style = "cozy warm acoustic"
            mood = "comfortable inviting"
        elif any(word in concept_lower or word in keywords_lower 
                 for word in ["energetic", "upbeat", "dynamic"]):
            style = "upbeat contemporary"
            mood = "energetic positive"
        else:
            style = "smooth ambient"
            mood = "calm professional"
        
        return {"brand": brand, "style": style, "mood": mood}

    def _generate_music_with_musicgen(self, prompt: str, duration: float = 10.0) -> str:
        """MusicGenìœ¼ë¡œ ì‹¤ì œ ìŒì•… ìƒì„±"""
        print(f"ğŸ¼ MusicGen ìŒì•… ìƒì„±: '{prompt[:50]}...'")
        
        try:
            # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
            output_dir = "data/output"
            os.makedirs(output_dir, exist_ok=True)
            
            # MusicGenìœ¼ë¡œ ìŒì•… ìƒì„±
            inputs = self.music_processor(
                text=[prompt],
                padding=True,
                return_tensors="pt",
            )
            
            # ìŒì•… ìƒì„± (duration ì´ˆ)
            audio_values = self.music_generator.generate(**inputs, max_new_tokens=int(duration * 50))  # ëŒ€ëµì ì¸ í† í° ìˆ˜
            
            # ì˜¤ë””ì˜¤ ë°ì´í„° ì¶”ì¶œ
            audio_data = audio_values[0, 0].cpu().numpy()
            
            # íŒŒì¼ëª… ìƒì„±
            safe_prompt = "".join(c for c in prompt if c.isalnum() or c in (' ', '-', '_'))[:30]
            filename = f"musicgen_{safe_prompt.replace(' ', '_')}.wav"
            filepath = os.path.join(output_dir, filename)
            
            # WAV íŒŒì¼ë¡œ ì €ì¥
            sample_rate = self.music_generator.config.audio_encoder.sampling_rate
            sf.write(filepath, audio_data, sample_rate)
            
            print(f"âœ… MusicGen ìŒì•… ìƒì„± ì™„ë£Œ: {filepath}")
            return filepath
            
        except Exception as e:
            print(f"âŒ MusicGen ìŒì•… ìƒì„± ì‹¤íŒ¨: {e}")
            raise e

    def _generate_music_with_basic_audio(self, prompt: str, duration: float = 10.0) -> str:
        """ê¸°ë³¸ ì˜¤ë””ì˜¤ í•©ì„±ìœ¼ë¡œ ìŒì•… ìƒì„±"""
        print(f"ğŸ¼ ê¸°ë³¸ ì˜¤ë””ì˜¤ í•©ì„±: '{prompt[:50]}...'")
        
        try:
            # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
            output_dir = "data/output"
            os.makedirs(output_dir, exist_ok=True)
            
            # í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ìŒì•… ìŠ¤íƒ€ì¼ ê²°ì •
            sample_rate = 44100
            audio_length = int(duration * sample_rate)
            t = np.linspace(0, duration, audio_length)
            
            # í”„ë¡¬í”„íŠ¸ì— ë”°ë¥¸ ì£¼íŒŒìˆ˜ ì„ íƒ
            if "cozy" in prompt.lower() or "warm" in prompt.lower():
                # ë”°ëœ»í•œ í™”ìŒ
                base_freqs = [220, 330, 440]  # A3, E4, A4
            elif "upbeat" in prompt.lower() or "energetic" in prompt.lower():
                # í™œê¸°ì°¬ í™”ìŒ
                base_freqs = [262, 330, 392]  # C4, E4, G4
            else:
                # í¸ì•ˆí•œ í™”ìŒ
                base_freqs = [196, 294, 392]  # G3, D4, G4
            
            # í™”ìŒ ìƒì„±
            audio = np.zeros(audio_length)
            for i, freq in enumerate(base_freqs):
                amplitude = 0.15 / (i + 1)  # ì ì  ì‘ì€ ë³¼ë¥¨
                # ì•½ê°„ì˜ ë³€ì¡° ì¶”ê°€ (ë” ìì—°ìŠ¤ëŸ½ê²Œ)
                modulation = 1 + 0.1 * np.sin(2 * np.pi * 0.5 * t)
                audio += amplitude * np.sin(2 * np.pi * freq * t * modulation)
            
            # í˜ì´ë“œ ì¸/ì•„ì›ƒ
            fade_samples = int(1.0 * sample_rate)
            audio[:fade_samples] *= np.linspace(0, 1, fade_samples)
            audio[-fade_samples:] *= np.linspace(1, 0, fade_samples)
            
            # íŒŒì¼ëª… ìƒì„±
            safe_prompt = "".join(c for c in prompt if c.isalnum() or c in (' ', '-', '_'))[:30]
            filename = f"basic_audio_{safe_prompt.replace(' ', '_')}.wav"
            filepath = os.path.join(output_dir, filename)
            
            # WAV íŒŒì¼ë¡œ ì €ì¥
            sf.write(filepath, audio, sample_rate)
            
            print(f"âœ… ê¸°ë³¸ ì˜¤ë””ì˜¤ í•©ì„± ì™„ë£Œ: {filepath}")
            return filepath
            
        except Exception as e:
            print(f"âŒ ê¸°ë³¸ ì˜¤ë””ì˜¤ í•©ì„± ì‹¤íŒ¨: {e}")
            raise e

    def _generate_mock_music(self) -> List[Dict[str, Any]]:
        """ëª©ì—… ìŒì•… ë°ì´í„° ìƒì„±"""
        return [
            {
                "section": "opening",
                "file_path": "data/temp/opening_music.wav",
                "duration": 8.0,
                "prompt": "cozy warm commercial intro",
                "style": {"brand": "commercial", "style": "warm", "mood": "inviting"},
                "engine": "mock"
            },
            {
                "section": "main",
                "file_path": "data/temp/main_music.wav", 
                "duration": 15.0,
                "prompt": "smooth background music",
                "style": {"brand": "commercial", "style": "ambient", "mood": "professional"},
                "engine": "mock"
            },
            {
                "section": "closing",
                "file_path": "data/temp/closing_music.wav",
                "duration": 5.0,
                "prompt": "memorable ending theme",
                "style": {"brand": "commercial", "style": "uplifting", "mood": "memorable"},
                "engine": "mock"
            }
        ]

    def generate_video(self, concept: str, images: List, voices: List, music: List) -> str:
        """ìµœì¢… ì˜ìƒ í•©ì„± (ëª©ì—…)"""
        print("ğŸ¬ ìµœì¢… ì˜ìƒ í•©ì„± ì¤‘...")
        time.sleep(3)
        
        output_path = "data/output/final_advertisement.mp4"
        
        print(f"ğŸ“¹ í•©ì„± ì •ë³´:")
        print(f"   - ì´ë¯¸ì§€: {len(images)}ê°œ")
        print(f"   - ìŒì„±: {len(voices)}ê°œ") 
        print(f"   - ìŒì•…: {len(music)}ê°œ")
        print(f"   - ìŒì•… ì—”ì§„: {music[0].get('engine', 'unknown') if music else 'none'}")
        print(f"   - ì¶œë ¥: {output_path}")
        
        print("âœ… ì˜ìƒ í•©ì„± ì™„ë£Œ")
        return output_path
    
    def test_connection(self) -> bool:
        """ì—°ê²° í…ŒìŠ¤íŠ¸"""
        print("ğŸ”— Testing connection...")
        time.sleep(0.5)
        print("âœ… Mock connection successful!")
        return True

def test_complete_system():
    """ì™„ì „í•œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª Complete AI Advertisement System Test - Multi-Engine")
    print("=" * 60)
    
    try:
        client = MockOpenAIClient()
        
        print("\n1ï¸âƒ£ ì—°ê²° í…ŒìŠ¤íŠ¸...")
        if not client.test_connection():
            return False
        
        print("\n2ï¸âƒ£ ê´‘ê³  ì»¨ì…‰ ìƒì„±...")
        concept = client.generate_concept("Starbucks", "winter, cozy, new menu")
        print("âœ… ì»¨ì…‰ ìƒì„± ì™„ë£Œ")
        
        print("\n3ï¸âƒ£ ì´ë¯¸ì§€ ìƒì„±...")
        images = client.generate_images(concept, count=3)
        print(f"âœ… ì´ë¯¸ì§€ {len(images)}ê°œ ìƒì„± ì™„ë£Œ")
        
        print("\n4ï¸âƒ£ ìŒì„± ë‚˜ë ˆì´ì…˜ ìƒì„±...")
        voices = client.generate_voice(concept)
        print(f"âœ… ìŒì„± {len(voices)}ê°œ ìƒì„± ì™„ë£Œ")
        
        print("\n5ï¸âƒ£ ë°°ê²½ìŒì•… ìƒì„±...")
        music = client.generate_music(concept, "winter, cozy")
        print(f"âœ… ìŒì•… {len(music)}ê°œ ìƒì„± ì™„ë£Œ")
        
        print("\n6ï¸âƒ£ ìµœì¢… ì˜ìƒ í•©ì„±...")
        video_path = client.generate_video(concept, images, voices, music)
        print(f"âœ… ì˜ìƒ ìƒì„± ì™„ë£Œ: {video_path}")
        
        print("\nğŸ‰ ì™„ì „í•œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        print(f"ğŸ’¡ ìŒì•… ìƒì„± ì—”ì§„: {MUSIC_GENERATOR_TYPE.upper()}")
        print(f"ğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤ì€ data/output/ í´ë”ì—ì„œ í™•ì¸í•˜ì„¸ìš”!")
        
        return True
        
    except Exception as e:
        print(f"ğŸ’¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        return False

if __name__ == "__main__":
    test_complete_system()