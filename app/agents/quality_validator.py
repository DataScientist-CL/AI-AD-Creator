# app/agents/quality_validator.py - faster-whisper ê¸°ë°˜ ìŒì„± í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ

from faster_whisper import WhisperModel
import os
import difflib
from typing import Dict, Any, Optional, List
import logging
import numpy as np
from pathlib import Path

# librosa import ì²˜ë¦¬ (ì„ íƒì )
try:
    import librosa
    LIBROSA_AVAILABLE = True
except ImportError:
    LIBROSA_AVAILABLE = False
    print("âš ï¸ librosaë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì˜¤ë””ì˜¤ ë¶„ì„ë§Œ ìˆ˜í–‰ë©ë‹ˆë‹¤.")

logger = logging.getLogger(__name__)

class AudioQualityValidator:
    """
    faster-whisperë¥¼ í™œìš©í•œ TTS ìŒì„± í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ
    """

    def __init__(self, whisper_model: str = "base"):
        print(f"ğŸ” AudioQualityValidator ì´ˆê¸°í™”:")
        print(f"  - Whisper ëª¨ë¸(faster-whisper): {whisper_model}")
        print(f"  - Librosa ì‚¬ìš© ê°€ëŠ¥: {LIBROSA_AVAILABLE}")

        try:
            self.whisper_model = WhisperModel(
                whisper_model,
                device="cpu",  # GPU ì‚¬ìš© ì‹œ "cuda"
                compute_type="int8"
            )
            self.available = True
            print("âœ… AudioQualityValidator: faster-whisper ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"faster-whisper ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.whisper_model = None
            self.available = False
            print("âŒ AudioQualityValidator: ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ - í’ˆì§ˆ ê²€ì¦ ë¹„í™œì„±í™”")

    def validate_audio_quality(self, audio_file_path: str, original_text: str, min_similarity: float = 0.8) -> Dict[str, Any]:
        if not self.available:
            return {
                "available": False,
                "message": "Whisper ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                "overall_score": 0.0,
                "passed": False
            }

        if not os.path.exists(audio_file_path):
            return {
                "available": True,
                "error": f"ìŒì„± íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_file_path}",
                "overall_score": 0.0,
                "passed": False
            }

        print(f"ğŸ” ìŒì„± í’ˆì§ˆ ê²€ì¦ ì‹œì‘: {Path(audio_file_path).name}")
        try:
            # 1. STT
            transcription_result = self._transcribe_audio(audio_file_path)

            # 2. í…ìŠ¤íŠ¸ ìœ ì‚¬ë„
            similarity_result = self._calculate_text_similarity(
                original_text,
                transcription_result["text"]
            )

            # 3. ì˜¤ë””ì˜¤ í’ˆì§ˆ ë¶„ì„
            audio_quality_result = self._analyze_audio_quality(audio_file_path)

            # 4. ì¢…í•© ì ìˆ˜
            overall_score = self._calculate_overall_score(
                similarity_result,
                audio_quality_result,
                transcription_result
            )

            return {
                "available": True,
                "audio_file": audio_file_path,
                "original_text": original_text,
                "transcribed_text": transcription_result["text"],
                "transcription_confidence": transcription_result.get("confidence", 0.0),
                "text_similarity": similarity_result,
                "audio_quality": audio_quality_result,
                "overall_score": overall_score,
                "passed": overall_score >= min_similarity,
                "min_similarity": min_similarity,
                "recommendations": self._generate_recommendations(
                    overall_score, similarity_result, audio_quality_result
                )
            }

        except Exception as e:
            logger.error(f"í’ˆì§ˆ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                "available": True,
                "error": str(e),
                "overall_score": 0.0,
                "passed": False
            }

    def _transcribe_audio(self, audio_file_path: str) -> Dict[str, Any]:
        print("  ğŸ¤ faster-whisper STT ì‹¤í–‰ ì¤‘...")
        try:
            segments, info = self.whisper_model.transcribe(audio_file_path, language="ko", beam_size=5)
            texts = []
            confidences = []

            for segment in segments:
                texts.append(segment.text.strip())
                if segment.avg_logprob is not None:
                    confidences.append(np.exp(min(0, segment.avg_logprob)))

            transcript_text = " ".join(texts)

            return {
                "text": transcript_text.strip(),
                "language": info.language,
                "segments": texts,
                "confidence": float(np.mean(confidences)) if confidences else 0.0
            }
        except Exception as e:
            logger.error(f"STT ì‹¤íŒ¨: {e}")
            return {
                "text": "",
                "error": str(e),
                "confidence": 0.0
            }

    def _calculate_text_similarity(self, original: str, transcribed: str) -> Dict[str, float]:
        print("  ğŸ“Š í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚° ì¤‘...")
        import re
        original_clean = re.sub(r'\s+', ' ', original.strip())
        transcribed_clean = re.sub(r'\s+', ' ', transcribed.strip())

        char_similarity = difflib.SequenceMatcher(None, original_clean, transcribed_clean).ratio()
        word_similarity = difflib.SequenceMatcher(None, original_clean.split(), transcribed_clean.split()).ratio()
        length_similarity = min(len(original_clean), len(transcribed_clean)) / max(len(original_clean), len(transcribed_clean)) if max(len(original_clean), len(transcribed_clean)) else 0

        return {
            "character_similarity": char_similarity,
            "word_similarity": word_similarity,
            "length_similarity": length_similarity,
            "average_similarity": (char_similarity + word_similarity + length_similarity) / 3
        }

    def _analyze_audio_quality(self, audio_file_path: str) -> Dict[str, Any]:
        print("  ğŸ”Š ì˜¤ë””ì˜¤ í’ˆì§ˆ ë¶„ì„ ì¤‘...")
        if not LIBROSA_AVAILABLE:
            return {
                "librosa_available": False,
                "quality_score": 0.5,
                "message": "librosa ì—†ìŒ"
            }
        try:
            y, sr = librosa.load(audio_file_path, sr=None)
            duration = librosa.get_duration(y=y, sr=sr)
            rms = librosa.feature.rms(y=y)[0]
            avg_rms = float(np.mean(rms))
            zcr = librosa.feature.zero_crossing_rate(y)[0]
            avg_zcr = float(np.mean(zcr))
            spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
            avg_spectral_centroid = float(np.mean(spectral_centroids))
            silence_ratio = np.sum(np.abs(y) < 0.01) / len(y)

            quality_score = self._calculate_audio_quality_score(
                avg_rms, avg_zcr, avg_spectral_centroid, silence_ratio, duration
            )

            return {
                "librosa_available": True,
                "duration": duration,
                "sample_rate": sr,
                "avg_rms": avg_rms,
                "avg_zero_crossing_rate": avg_zcr,
                "avg_spectral_centroid": avg_spectral_centroid,
                "silence_ratio": silence_ratio,
                "quality_score": quality_score
            }

        except Exception as e:
            logger.error(f"ì˜¤ë””ì˜¤ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "librosa_available": True,
                "error": str(e),
                "quality_score": 0.5
            }

    def _calculate_overall_score(self, similarity_result: Dict, audio_quality_result: Dict, transcription_result: Dict) -> float:
        weights = {
            "text_similarity": 0.6,
            "audio_quality": 0.3,
            "transcription_confidence": 0.1
        }
        return round(
            similarity_result.get("average_similarity", 0) * weights["text_similarity"] +
            audio_quality_result.get("quality_score", 0.5) * weights["audio_quality"] +
            transcription_result.get("confidence", 0.0) * weights["transcription_confidence"],
            3
        )

    def _calculate_audio_quality_score(self, avg_rms: float, avg_zcr: float, avg_spectral_centroid: float, silence_ratio: float, duration: float) -> float:
        score = 0.0
        if 0.01 <= avg_rms <= 0.3:
            score += 0.3
        if silence_ratio < 0.1:
            score += 0.2
        elif silence_ratio < 0.2:
            score += 0.1
        if 0.05 <= avg_zcr <= 0.2:
            score += 0.2
        if 1000 <= avg_spectral_centroid <= 4000:
            score += 0.2
        if 1.0 <= duration <= 30.0:
            score += 0.1
        return min(1.0, score)

    def _generate_recommendations(self, overall_score: float, similarity_result: Dict, audio_quality_result: Dict) -> List[str]:
        recommendations = []
        if overall_score < 0.6:
            recommendations.append("ì „ë°˜ì ì¸ í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤. ì¬ìƒì„±ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        if similarity_result.get("character_similarity", 0) < 0.7:
            recommendations.append("í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ë°œìŒì´ ë¶€ì •í™•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        if audio_quality_result.get("avg_rms", 0) < 0.01:
            recommendations.append("ìŒëŸ‰ì´ ë„ˆë¬´ ë‚®ìŠµë‹ˆë‹¤.")
        elif audio_quality_result.get("avg_rms", 0) > 0.3:
            recommendations.append("ìŒëŸ‰ì´ ë„ˆë¬´ í½ë‹ˆë‹¤.")
        if audio_quality_result.get("silence_ratio", 0) > 0.2:
            recommendations.append("ë¬´ìŒ êµ¬ê°„ì´ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤.")
        if not recommendations:
            recommendations.append("í’ˆì§ˆì´ ì–‘í˜¸í•©ë‹ˆë‹¤.")
        return recommendations